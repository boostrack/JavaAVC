package org.javaavc.gen.avfilter;
import com.ochafik.lang.jnaerator.runtime.NativeSize;
import com.sun.jna.Callback;
import com.sun.jna.Library;
import com.sun.jna.Pointer;
import com.sun.jna.PointerType;
import com.sun.jna.ptr.IntByReference;
import com.sun.jna.ptr.LongByReference;
import com.sun.jna.ptr.PointerByReference;
import java.nio.ByteBuffer;
import java.nio.IntBuffer;
import java.nio.LongBuffer;
/**
 * JNA Wrapper for library <b>Libavfilter</b><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> , <a href="http://rococoa.dev.java.net/">Rococoa</a>, or <a href="http://jna.dev.java.net/">JNA</a>.
 */
public interface LibavfilterLibrary extends Library {
	/** enum values */
	public static interface AVMediaType {
		/** < Usually treated as AVMEDIA_TYPE_DATA */
		public static final int AVMEDIA_TYPE_UNKNOWN = -1;
		public static final int AVMEDIA_TYPE_VIDEO = 0;
		public static final int AVMEDIA_TYPE_AUDIO = 1;
		/** < Opaque data information usually continuous */
		public static final int AVMEDIA_TYPE_DATA = 2;
		public static final int AVMEDIA_TYPE_SUBTITLE = 3;
		/** < Opaque data information usually sparse */
		public static final int AVMEDIA_TYPE_ATTACHMENT = 4;
		public static final int AVMEDIA_TYPE_NB = 5;
	};
	/** enum values */
	public static interface AVPictureType {
		/** < Undefined */
		public static final int AV_PICTURE_TYPE_NONE = 0;
		/** < Intra */
		public static final int AV_PICTURE_TYPE_I = 1;
		/** < Predicted */
		public static final int AV_PICTURE_TYPE_P = 2;
		/** < Bi-dir predicted */
		public static final int AV_PICTURE_TYPE_B = 3;
		/** < S(GMC)-VOP MPEG4 */
		public static final int AV_PICTURE_TYPE_S = 4;
		/** < Switching Intra */
		public static final int AV_PICTURE_TYPE_SI = 5;
		/** < Switching Predicted */
		public static final int AV_PICTURE_TYPE_SP = 6;
		/** < BI type */
		public static final int AV_PICTURE_TYPE_BI = 7;
	};
	/** enum values */
	public static interface AVRounding {
		/** < Round toward zero. */
		public static final int AV_ROUND_ZERO = 0;
		/** < Round away from zero. */
		public static final int AV_ROUND_INF = 1;
		/** < Round toward -infinity. */
		public static final int AV_ROUND_DOWN = 2;
		/** < Round toward +infinity. */
		public static final int AV_ROUND_UP = 3;
		/** < Round to nearest and halfway cases away from zero. */
		public static final int AV_ROUND_NEAR_INF = 5;
		/** < Flag to pass INT64_MIN/MAX through instead of rescaling, this avoids special cases for AV_NOPTS_VALUE */
		public static final int AV_ROUND_PASS_MINMAX = 8192;
	};
	/** enum values */
	public static interface AVClassCategory {
		public static final int AV_CLASS_CATEGORY_NA = 0;
		public static final int AV_CLASS_CATEGORY_INPUT = 1;
		public static final int AV_CLASS_CATEGORY_OUTPUT = 2;
		public static final int AV_CLASS_CATEGORY_MUXER = 3;
		public static final int AV_CLASS_CATEGORY_DEMUXER = 4;
		public static final int AV_CLASS_CATEGORY_ENCODER = 5;
		public static final int AV_CLASS_CATEGORY_DECODER = 6;
		public static final int AV_CLASS_CATEGORY_FILTER = 7;
		public static final int AV_CLASS_CATEGORY_BITSTREAM_FILTER = 8;
		public static final int AV_CLASS_CATEGORY_SWSCALER = 9;
		public static final int AV_CLASS_CATEGORY_SWRESAMPLER = 10;
		public static final int AV_CLASS_CATEGORY_NB = 11;
	};
	/**
	 * Pixel format.<br>
	 * * @note<br>
	 * PIX_FMT_RGB32 is handled in an endian-specific manner. An RGBA<br>
	 * color is put together as:<br>
	 *  (A << 24) | (R << 16) | (G << 8) | B<br>
	 * This is stored as BGRA on little-endian CPU architectures and ARGB on<br>
	 * big-endian CPUs.<br>
	 * * @par<br>
	 * When the pixel format is palettized RGB (PIX_FMT_PAL8), the palettized<br>
	 * image data is stored in AVFrame.data[0]. The palette is transported in<br>
	 * AVFrame.data[1], is 1024 bytes long (256 4-byte entries) and is<br>
	 * formatted the same as in PIX_FMT_RGB32 described above (i.e., it is<br>
	 * also endian-specific). Note also that the individual RGB palette<br>
	 * components stored in AVFrame.data[1] should be in the range 0..255.<br>
	 * This is important as many custom PAL8 video codecs that were designed<br>
	 * to run on the IBM VGA graphics adapter use 6-bit palette components.<br>
	 * * @par<br>
	 * For all the 8bit per pixel formats, an RGB32 palette is in data[1] like<br>
	 * for pal8. This palette is filled in automatically by the function<br>
	 * allocating the picture.<br>
	 * * @note<br>
	 * Make sure that all newly added big-endian formats have pix_fmt & 1 == 1<br>
	 * and that all newly added little-endian formats have pix_fmt & 1 == 0.<br>
	 * This allows simpler detection of big vs little-endian.<br>
	 * enum values
	 */
	public static interface AVPixelFormat {
		public static final int AV_PIX_FMT_NONE = -1;
		/** < planar YUV 4:2:0, 12bpp, (1 Cr & Cb sample per 2x2 Y samples) */
		public static final int AV_PIX_FMT_YUV420P = 0;
		/** < packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr */
		public static final int AV_PIX_FMT_YUYV422 = 1;
		/** < packed RGB 8:8:8, 24bpp, RGBRGB... */
		public static final int AV_PIX_FMT_RGB24 = 2;
		/** < packed RGB 8:8:8, 24bpp, BGRBGR... */
		public static final int AV_PIX_FMT_BGR24 = 3;
		/** < planar YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples) */
		public static final int AV_PIX_FMT_YUV422P = 4;
		/** < planar YUV 4:4:4, 24bpp, (1 Cr & Cb sample per 1x1 Y samples) */
		public static final int AV_PIX_FMT_YUV444P = 5;
		/** < planar YUV 4:1:0,  9bpp, (1 Cr & Cb sample per 4x4 Y samples) */
		public static final int AV_PIX_FMT_YUV410P = 6;
		/** < planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples) */
		public static final int AV_PIX_FMT_YUV411P = 7;
		/** <        Y        ,  8bpp */
		public static final int AV_PIX_FMT_GRAY8 = 8;
		/** <        Y        ,  1bpp, 0 is white, 1 is black, in each byte pixels are ordered from the msb to the lsb */
		public static final int AV_PIX_FMT_MONOWHITE = 9;
		/** <        Y        ,  1bpp, 0 is black, 1 is white, in each byte pixels are ordered from the msb to the lsb */
		public static final int AV_PIX_FMT_MONOBLACK = 10;
		/** < 8 bit with PIX_FMT_RGB32 palette */
		public static final int AV_PIX_FMT_PAL8 = 11;
		/** < planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV420P and setting color_range */
		public static final int AV_PIX_FMT_YUVJ420P = 12;
		/** < planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV422P and setting color_range */
		public static final int AV_PIX_FMT_YUVJ422P = 13;
		/** < planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV444P and setting color_range */
		public static final int AV_PIX_FMT_YUVJ444P = 14;
		/** < XVideo Motion Acceleration via common packet passing */
		public static final int AV_PIX_FMT_XVMC_MPEG2_MC = 15;
		public static final int AV_PIX_FMT_XVMC_MPEG2_IDCT = 16;
		/** < packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1 */
		public static final int AV_PIX_FMT_UYVY422 = 17;
		/** < packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3 */
		public static final int AV_PIX_FMT_UYYVYY411 = 18;
		/** < packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb) */
		public static final int AV_PIX_FMT_BGR8 = 19;
		/** < packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits */
		public static final int AV_PIX_FMT_BGR4 = 20;
		/** < packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb) */
		public static final int AV_PIX_FMT_BGR4_BYTE = 21;
		/** < packed RGB 3:3:2,  8bpp, (msb)2R 3G 3B(lsb) */
		public static final int AV_PIX_FMT_RGB8 = 22;
		/** < packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits */
		public static final int AV_PIX_FMT_RGB4 = 23;
		/** < packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb) */
		public static final int AV_PIX_FMT_RGB4_BYTE = 24;
		/** < planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V) */
		public static final int AV_PIX_FMT_NV12 = 25;
		/** < as above, but U and V bytes are swapped */
		public static final int AV_PIX_FMT_NV21 = 26;
		/** < packed ARGB 8:8:8:8, 32bpp, ARGBARGB... */
		public static final int AV_PIX_FMT_ARGB = 27;
		/** < packed RGBA 8:8:8:8, 32bpp, RGBARGBA... */
		public static final int AV_PIX_FMT_RGBA = 28;
		/** < packed ABGR 8:8:8:8, 32bpp, ABGRABGR... */
		public static final int AV_PIX_FMT_ABGR = 29;
		/** < packed BGRA 8:8:8:8, 32bpp, BGRABGRA... */
		public static final int AV_PIX_FMT_BGRA = 30;
		/** <        Y        , 16bpp, big-endian */
		public static final int AV_PIX_FMT_GRAY16BE = 31;
		/** <        Y        , 16bpp, little-endian */
		public static final int AV_PIX_FMT_GRAY16LE = 32;
		/** < planar YUV 4:4:0 (1 Cr & Cb sample per 1x2 Y samples) */
		public static final int AV_PIX_FMT_YUV440P = 33;
		/** < planar YUV 4:4:0 full scale (JPEG), deprecated in favor of PIX_FMT_YUV440P and setting color_range */
		public static final int AV_PIX_FMT_YUVJ440P = 34;
		/** < planar YUV 4:2:0, 20bpp, (1 Cr & Cb sample per 2x2 Y & A samples) */
		public static final int AV_PIX_FMT_YUVA420P = 35;
		/** < H.264 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VDPAU_H264 = 36;
		/** < MPEG-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VDPAU_MPEG1 = 37;
		/** < MPEG-2 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VDPAU_MPEG2 = 38;
		/** < WMV3 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VDPAU_WMV3 = 39;
		/** < VC-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VDPAU_VC1 = 40;
		/** < packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as big-endian */
		public static final int AV_PIX_FMT_RGB48BE = 41;
		/** < packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as little-endian */
		public static final int AV_PIX_FMT_RGB48LE = 42;
		/** < packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), big-endian */
		public static final int AV_PIX_FMT_RGB565BE = 43;
		/** < packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), little-endian */
		public static final int AV_PIX_FMT_RGB565LE = 44;
		/** < packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), big-endian, most significant bit to 0 */
		public static final int AV_PIX_FMT_RGB555BE = 45;
		/** < packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), little-endian, most significant bit to 0 */
		public static final int AV_PIX_FMT_RGB555LE = 46;
		/** < packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), big-endian */
		public static final int AV_PIX_FMT_BGR565BE = 47;
		/** < packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), little-endian */
		public static final int AV_PIX_FMT_BGR565LE = 48;
		/** < packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), big-endian, most significant bit to 1 */
		public static final int AV_PIX_FMT_BGR555BE = 49;
		/** < packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), little-endian, most significant bit to 1 */
		public static final int AV_PIX_FMT_BGR555LE = 50;
		/** < HW acceleration through VA API at motion compensation entry-point, Picture.data[3] contains a vaapi_render_state struct which contains macroblocks as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VAAPI_MOCO = 51;
		/** < HW acceleration through VA API at IDCT entry-point, Picture.data[3] contains a vaapi_render_state struct which contains fields extracted from headers */
		public static final int AV_PIX_FMT_VAAPI_IDCT = 52;
		/** < HW decoding through VA API, Picture.data[3] contains a vaapi_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VAAPI_VLD = 53;
		/** < planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV420P16LE = 54;
		/** < planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV420P16BE = 55;
		/** < planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV422P16LE = 56;
		/** < planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV422P16BE = 57;
		/** < planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV444P16LE = 58;
		/** < planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV444P16BE = 59;
		/** < MPEG4 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int AV_PIX_FMT_VDPAU_MPEG4 = 60;
		/** < HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 pointer */
		public static final int AV_PIX_FMT_DXVA2_VLD = 61;
		/** < packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), little-endian, most significant bits to 0 */
		public static final int AV_PIX_FMT_RGB444LE = 62;
		/** < packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), big-endian, most significant bits to 0 */
		public static final int AV_PIX_FMT_RGB444BE = 63;
		/** < packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), little-endian, most significant bits to 1 */
		public static final int AV_PIX_FMT_BGR444LE = 64;
		/** < packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), big-endian, most significant bits to 1 */
		public static final int AV_PIX_FMT_BGR444BE = 65;
		/** < 8bit gray, 8bit alpha */
		public static final int AV_PIX_FMT_GRAY8A = 66;
		/** < packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian */
		public static final int AV_PIX_FMT_BGR48BE = 67;
		/** < packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian */
		public static final int AV_PIX_FMT_BGR48LE = 68;
		/**
		 * is better<br>
		 * < planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
		 */
		public static final int AV_PIX_FMT_YUV420P9BE = 69;
		/** < planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV420P9LE = 70;
		/** < planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV420P10BE = 71;
		/** < planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV420P10LE = 72;
		/** < planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV422P10BE = 73;
		/** < planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV422P10LE = 74;
		/** < planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV444P9BE = 75;
		/** < planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV444P9LE = 76;
		/** < planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV444P10BE = 77;
		/** < planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV444P10LE = 78;
		/** < planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV422P9BE = 79;
		/** < planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV422P9LE = 80;
		/** < hardware decoding through VDA */
		public static final int AV_PIX_FMT_VDA_VLD = 81;
		/** < planar GBR 4:4:4 24bpp */
		public static final int AV_PIX_FMT_GBRP = 82;
		/** < planar GBR 4:4:4 27bpp, big-endian */
		public static final int AV_PIX_FMT_GBRP9BE = 83;
		/** < planar GBR 4:4:4 27bpp, little-endian */
		public static final int AV_PIX_FMT_GBRP9LE = 84;
		/** < planar GBR 4:4:4 30bpp, big-endian */
		public static final int AV_PIX_FMT_GBRP10BE = 85;
		/** < planar GBR 4:4:4 30bpp, little-endian */
		public static final int AV_PIX_FMT_GBRP10LE = 86;
		/** < planar GBR 4:4:4 48bpp, big-endian */
		public static final int AV_PIX_FMT_GBRP16BE = 87;
		/** < planar GBR 4:4:4 48bpp, little-endian */
		public static final int AV_PIX_FMT_GBRP16LE = 88;
		/**
		 * duplicated pixel formats for compatibility with libav.<br>
		 * FFmpeg supports these formats since May 8 2012 and Jan 28 2012 (commits f9ca1ac7 and 143a5c55)<br>
		 * Libav added them Oct 12 2012 with incompatible values (commit 6d5600e85)<br>
		 * < planar YUV 4:2:2 24bpp, (1 Cr & Cb sample per 2x1 Y & A samples)
		 */
		public static final int AV_PIX_FMT_YUVA422P_LIBAV = 89;
		/** < planar YUV 4:4:4 32bpp, (1 Cr & Cb sample per 1x1 Y & A samples) */
		public static final int AV_PIX_FMT_YUVA444P_LIBAV = 90;
		/** < planar YUV 4:2:0 22.5bpp, (1 Cr & Cb sample per 2x2 Y & A samples), big-endian */
		public static final int AV_PIX_FMT_YUVA420P9BE = 91;
		/** < planar YUV 4:2:0 22.5bpp, (1 Cr & Cb sample per 2x2 Y & A samples), little-endian */
		public static final int AV_PIX_FMT_YUVA420P9LE = 92;
		/** < planar YUV 4:2:2 27bpp, (1 Cr & Cb sample per 2x1 Y & A samples), big-endian */
		public static final int AV_PIX_FMT_YUVA422P9BE = 93;
		/** < planar YUV 4:2:2 27bpp, (1 Cr & Cb sample per 2x1 Y & A samples), little-endian */
		public static final int AV_PIX_FMT_YUVA422P9LE = 94;
		/** < planar YUV 4:4:4 36bpp, (1 Cr & Cb sample per 1x1 Y & A samples), big-endian */
		public static final int AV_PIX_FMT_YUVA444P9BE = 95;
		/** < planar YUV 4:4:4 36bpp, (1 Cr & Cb sample per 1x1 Y & A samples), little-endian */
		public static final int AV_PIX_FMT_YUVA444P9LE = 96;
		/** < planar YUV 4:2:0 25bpp, (1 Cr & Cb sample per 2x2 Y & A samples, big-endian) */
		public static final int AV_PIX_FMT_YUVA420P10BE = 97;
		/** < planar YUV 4:2:0 25bpp, (1 Cr & Cb sample per 2x2 Y & A samples, little-endian) */
		public static final int AV_PIX_FMT_YUVA420P10LE = 98;
		/** < planar YUV 4:2:2 30bpp, (1 Cr & Cb sample per 2x1 Y & A samples, big-endian) */
		public static final int AV_PIX_FMT_YUVA422P10BE = 99;
		/** < planar YUV 4:2:2 30bpp, (1 Cr & Cb sample per 2x1 Y & A samples, little-endian) */
		public static final int AV_PIX_FMT_YUVA422P10LE = 100;
		/** < planar YUV 4:4:4 40bpp, (1 Cr & Cb sample per 1x1 Y & A samples, big-endian) */
		public static final int AV_PIX_FMT_YUVA444P10BE = 101;
		/** < planar YUV 4:4:4 40bpp, (1 Cr & Cb sample per 1x1 Y & A samples, little-endian) */
		public static final int AV_PIX_FMT_YUVA444P10LE = 102;
		/** < planar YUV 4:2:0 40bpp, (1 Cr & Cb sample per 2x2 Y & A samples, big-endian) */
		public static final int AV_PIX_FMT_YUVA420P16BE = 103;
		/** < planar YUV 4:2:0 40bpp, (1 Cr & Cb sample per 2x2 Y & A samples, little-endian) */
		public static final int AV_PIX_FMT_YUVA420P16LE = 104;
		/** < planar YUV 4:2:2 48bpp, (1 Cr & Cb sample per 2x1 Y & A samples, big-endian) */
		public static final int AV_PIX_FMT_YUVA422P16BE = 105;
		/** < planar YUV 4:2:2 48bpp, (1 Cr & Cb sample per 2x1 Y & A samples, little-endian) */
		public static final int AV_PIX_FMT_YUVA422P16LE = 106;
		/** < planar YUV 4:4:4 64bpp, (1 Cr & Cb sample per 1x1 Y & A samples, big-endian) */
		public static final int AV_PIX_FMT_YUVA444P16BE = 107;
		/** < planar YUV 4:4:4 64bpp, (1 Cr & Cb sample per 1x1 Y & A samples, little-endian) */
		public static final int AV_PIX_FMT_YUVA444P16LE = 108;
		/** < HW acceleration through VDPAU, Picture.data[3] contains a VdpVideoSurface */
		public static final int AV_PIX_FMT_VDPAU = 109;
		/** < packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as little-endian, the 4 lower bits are set to 0 */
		public static final int AV_PIX_FMT_XYZ12LE = 110;
		/** < packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as big-endian, the 4 lower bits are set to 0 */
		public static final int AV_PIX_FMT_XYZ12BE = 111;
		/** < packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian */
		public static final int AV_PIX_FMT_RGBA64BE = 0x123;
		/** < packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian */
		public static final int AV_PIX_FMT_RGBA64LE = (0x123 + 1);
		/** < packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian */
		public static final int AV_PIX_FMT_BGRA64BE = (0x123 + 2);
		/** < packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian */
		public static final int AV_PIX_FMT_BGRA64LE = (0x123 + 3);
		/** < packed RGB 8:8:8, 32bpp, 0RGB0RGB... */
		public static final int AV_PIX_FMT_0RGB = 0x123 + 4;
		/** < packed RGB 8:8:8, 32bpp, RGB0RGB0... */
		public static final int AV_PIX_FMT_RGB0 = (0x123 + 4 + 1);
		/** < packed BGR 8:8:8, 32bpp, 0BGR0BGR... */
		public static final int AV_PIX_FMT_0BGR = (0x123 + 4 + 2);
		/** < packed BGR 8:8:8, 32bpp, BGR0BGR0... */
		public static final int AV_PIX_FMT_BGR0 = (0x123 + 4 + 3);
		/** < planar YUV 4:4:4 32bpp, (1 Cr & Cb sample per 1x1 Y & A samples) */
		public static final int AV_PIX_FMT_YUVA444P = (0x123 + 4 + 4);
		/** < planar YUV 4:2:2 24bpp, (1 Cr & Cb sample per 2x1 Y & A samples) */
		public static final int AV_PIX_FMT_YUVA422P = (0x123 + 4 + 5);
		/** < planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV420P12BE = (0x123 + 4 + 6);
		/** < planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV420P12LE = (0x123 + 4 + 7);
		/** < planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV420P14BE = (0x123 + 4 + 8);
		/** < planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV420P14LE = (0x123 + 4 + 9);
		/** < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV422P12BE = (0x123 + 4 + 10);
		/** < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV422P12LE = (0x123 + 4 + 11);
		/** < planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV422P14BE = (0x123 + 4 + 12);
		/** < planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV422P14LE = (0x123 + 4 + 13);
		/** < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV444P12BE = (0x123 + 4 + 14);
		/** < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV444P12LE = (0x123 + 4 + 15);
		/** < planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int AV_PIX_FMT_YUV444P14BE = (0x123 + 4 + 16);
		/** < planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int AV_PIX_FMT_YUV444P14LE = (0x123 + 4 + 17);
		/** < planar GBR 4:4:4 36bpp, big-endian */
		public static final int AV_PIX_FMT_GBRP12BE = (0x123 + 4 + 18);
		/** < planar GBR 4:4:4 36bpp, little-endian */
		public static final int AV_PIX_FMT_GBRP12LE = (0x123 + 4 + 19);
		/** < planar GBR 4:4:4 42bpp, big-endian */
		public static final int AV_PIX_FMT_GBRP14BE = (0x123 + 4 + 20);
		/** < planar GBR 4:4:4 42bpp, little-endian */
		public static final int AV_PIX_FMT_GBRP14LE = (0x123 + 4 + 21);
		/** < planar GBRA 4:4:4:4 32bpp */
		public static final int AV_PIX_FMT_GBRAP = (0x123 + 4 + 22);
		/** < planar GBRA 4:4:4:4 64bpp, big-endian */
		public static final int AV_PIX_FMT_GBRAP16BE = (0x123 + 4 + 23);
		/** < planar GBRA 4:4:4:4 64bpp, little-endian */
		public static final int AV_PIX_FMT_GBRAP16LE = (0x123 + 4 + 24);
		/** < planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples) full scale (JPEG), deprecated in favor of PIX_FMT_YUV411P and setting color_range */
		public static final int AV_PIX_FMT_YUVJ411P = (0x123 + 4 + 25);
		/** < number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions */
		public static final int AV_PIX_FMT_NB = (0x123 + 4 + 26);
		/**
		 * This header exists to prevent new pixel formats from being accidentally added<br>
		 * to the deprecated list.<br>
		 * Do not include it directly. It will be removed on next major bump<br>
		 * * Do not add new items to this list. Use the AVPixelFormat enum instead.
		 */
		public static final int PIX_FMT_NONE = (int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE;
		/** < planar YUV 4:2:0, 12bpp, (1 Cr & Cb sample per 2x2 Y samples) */
		public static final int PIX_FMT_YUV420P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 1);
		/** < packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr */
		public static final int PIX_FMT_YUYV422 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 2);
		/** < packed RGB 8:8:8, 24bpp, RGBRGB... */
		public static final int PIX_FMT_RGB24 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 3);
		/** < packed RGB 8:8:8, 24bpp, BGRBGR... */
		public static final int PIX_FMT_BGR24 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 4);
		/** < planar YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples) */
		public static final int PIX_FMT_YUV422P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 5);
		/** < planar YUV 4:4:4, 24bpp, (1 Cr & Cb sample per 1x1 Y samples) */
		public static final int PIX_FMT_YUV444P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 6);
		/** < planar YUV 4:1:0,  9bpp, (1 Cr & Cb sample per 4x4 Y samples) */
		public static final int PIX_FMT_YUV410P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 7);
		/** < planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples) */
		public static final int PIX_FMT_YUV411P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 8);
		/** <        Y        ,  8bpp */
		public static final int PIX_FMT_GRAY8 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 9);
		/** <        Y        ,  1bpp, 0 is white, 1 is black, in each byte pixels are ordered from the msb to the lsb */
		public static final int PIX_FMT_MONOWHITE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 10);
		/** <        Y        ,  1bpp, 0 is black, 1 is white, in each byte pixels are ordered from the msb to the lsb */
		public static final int PIX_FMT_MONOBLACK = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 11);
		/** < 8 bit with PIX_FMT_RGB32 palette */
		public static final int PIX_FMT_PAL8 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 12);
		/** < planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV420P and setting color_range */
		public static final int PIX_FMT_YUVJ420P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 13);
		/** < planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV422P and setting color_range */
		public static final int PIX_FMT_YUVJ422P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 14);
		/** < planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV444P and setting color_range */
		public static final int PIX_FMT_YUVJ444P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 15);
		/** < XVideo Motion Acceleration via common packet passing */
		public static final int PIX_FMT_XVMC_MPEG2_MC = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 16);
		public static final int PIX_FMT_XVMC_MPEG2_IDCT = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 17);
		/** < packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1 */
		public static final int PIX_FMT_UYVY422 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 18);
		/** < packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3 */
		public static final int PIX_FMT_UYYVYY411 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 19);
		/** < packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb) */
		public static final int PIX_FMT_BGR8 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 20);
		/** < packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits */
		public static final int PIX_FMT_BGR4 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 21);
		/** < packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb) */
		public static final int PIX_FMT_BGR4_BYTE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 22);
		/** < packed RGB 3:3:2,  8bpp, (msb)2R 3G 3B(lsb) */
		public static final int PIX_FMT_RGB8 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 23);
		/** < packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits */
		public static final int PIX_FMT_RGB4 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 24);
		/** < packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb) */
		public static final int PIX_FMT_RGB4_BYTE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 25);
		/** < planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V) */
		public static final int PIX_FMT_NV12 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 26);
		/** < as above, but U and V bytes are swapped */
		public static final int PIX_FMT_NV21 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 27);
		/** < packed ARGB 8:8:8:8, 32bpp, ARGBARGB... */
		public static final int PIX_FMT_ARGB = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 28);
		/** < packed RGBA 8:8:8:8, 32bpp, RGBARGBA... */
		public static final int PIX_FMT_RGBA = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 29);
		/** < packed ABGR 8:8:8:8, 32bpp, ABGRABGR... */
		public static final int PIX_FMT_ABGR = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 30);
		/** < packed BGRA 8:8:8:8, 32bpp, BGRABGRA... */
		public static final int PIX_FMT_BGRA = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 31);
		/** <        Y        , 16bpp, big-endian */
		public static final int PIX_FMT_GRAY16BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 32);
		/** <        Y        , 16bpp, little-endian */
		public static final int PIX_FMT_GRAY16LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 33);
		/** < planar YUV 4:4:0 (1 Cr & Cb sample per 1x2 Y samples) */
		public static final int PIX_FMT_YUV440P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 34);
		/** < planar YUV 4:4:0 full scale (JPEG), deprecated in favor of PIX_FMT_YUV440P and setting color_range */
		public static final int PIX_FMT_YUVJ440P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 35);
		/** < planar YUV 4:2:0, 20bpp, (1 Cr & Cb sample per 2x2 Y & A samples) */
		public static final int PIX_FMT_YUVA420P = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 36);
		/** < H.264 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VDPAU_H264 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 37);
		/** < MPEG-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VDPAU_MPEG1 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 38);
		/** < MPEG-2 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VDPAU_MPEG2 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 39);
		/** < WMV3 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VDPAU_WMV3 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 40);
		/** < VC-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VDPAU_VC1 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 41);
		/** < packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as big-endian */
		public static final int PIX_FMT_RGB48BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 42);
		/** < packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as little-endian */
		public static final int PIX_FMT_RGB48LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 43);
		/** < packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), big-endian */
		public static final int PIX_FMT_RGB565BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 44);
		/** < packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), little-endian */
		public static final int PIX_FMT_RGB565LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 45);
		/** < packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), big-endian, most significant bit to 0 */
		public static final int PIX_FMT_RGB555BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 46);
		/** < packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), little-endian, most significant bit to 0 */
		public static final int PIX_FMT_RGB555LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 47);
		/** < packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), big-endian */
		public static final int PIX_FMT_BGR565BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 48);
		/** < packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), little-endian */
		public static final int PIX_FMT_BGR565LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 49);
		/** < packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), big-endian, most significant bit to 1 */
		public static final int PIX_FMT_BGR555BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 50);
		/** < packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), little-endian, most significant bit to 1 */
		public static final int PIX_FMT_BGR555LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 51);
		/** < HW acceleration through VA API at motion compensation entry-point, Picture.data[3] contains a vaapi_render_state struct which contains macroblocks as well as various fields extracted from headers */
		public static final int PIX_FMT_VAAPI_MOCO = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 52);
		/** < HW acceleration through VA API at IDCT entry-point, Picture.data[3] contains a vaapi_render_state struct which contains fields extracted from headers */
		public static final int PIX_FMT_VAAPI_IDCT = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 53);
		/** < HW decoding through VA API, Picture.data[3] contains a vaapi_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VAAPI_VLD = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 54);
		/** < planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int PIX_FMT_YUV420P16LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 55);
		/** < planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int PIX_FMT_YUV420P16BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 56);
		/** < planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV422P16LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 57);
		/** < planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV422P16BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 58);
		/** < planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV444P16LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 59);
		/** < planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV444P16BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 60);
		/** < MPEG4 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers */
		public static final int PIX_FMT_VDPAU_MPEG4 = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 61);
		/** < HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 pointer */
		public static final int PIX_FMT_DXVA2_VLD = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 62);
		/** < packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), little-endian, most significant bits to 0 */
		public static final int PIX_FMT_RGB444LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 63);
		/** < packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), big-endian, most significant bits to 0 */
		public static final int PIX_FMT_RGB444BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 64);
		/** < packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), little-endian, most significant bits to 1 */
		public static final int PIX_FMT_BGR444LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 65);
		/** < packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), big-endian, most significant bits to 1 */
		public static final int PIX_FMT_BGR444BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 66);
		/** < 8bit gray, 8bit alpha */
		public static final int PIX_FMT_GRAY8A = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 67);
		/** < packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian */
		public static final int PIX_FMT_BGR48BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 68);
		/** < packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian */
		public static final int PIX_FMT_BGR48LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 69);
		/**
		 * is better<br>
		 * < planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
		 */
		public static final int PIX_FMT_YUV420P9BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 70);
		/** < planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int PIX_FMT_YUV420P9LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 71);
		/** < planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int PIX_FMT_YUV420P10BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 72);
		/** < planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int PIX_FMT_YUV420P10LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 73);
		/** < planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV422P10BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 74);
		/** < planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV422P10LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 75);
		/** < planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV444P9BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 76);
		/** < planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV444P9LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 77);
		/** < planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV444P10BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 78);
		/** < planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV444P10LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 79);
		/** < planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV422P9BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 80);
		/** < planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV422P9LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 81);
		/** < hardware decoding through VDA */
		public static final int PIX_FMT_VDA_VLD = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 82);
		/** < planar GBR 4:4:4 24bpp */
		public static final int PIX_FMT_GBRP = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 83);
		/** < planar GBR 4:4:4 27bpp, big endian */
		public static final int PIX_FMT_GBRP9BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 84);
		/** < planar GBR 4:4:4 27bpp, little endian */
		public static final int PIX_FMT_GBRP9LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 85);
		/** < planar GBR 4:4:4 30bpp, big endian */
		public static final int PIX_FMT_GBRP10BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 86);
		/** < planar GBR 4:4:4 30bpp, little endian */
		public static final int PIX_FMT_GBRP10LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 87);
		/** < planar GBR 4:4:4 48bpp, big endian */
		public static final int PIX_FMT_GBRP16BE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 88);
		/** < planar GBR 4:4:4 48bpp, little endian */
		public static final int PIX_FMT_GBRP16LE = ((int)LibavfilterLibrary.AVPixelFormat.AV_PIX_FMT_NONE + 89);
		/** < packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian */
		public static final int PIX_FMT_RGBA64BE = 0x123;
		/** < packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian */
		public static final int PIX_FMT_RGBA64LE = (0x123 + 1);
		/** < packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian */
		public static final int PIX_FMT_BGRA64BE = (0x123 + 2);
		/** < packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian */
		public static final int PIX_FMT_BGRA64LE = (0x123 + 3);
		/** < packed RGB 8:8:8, 32bpp, 0RGB0RGB... */
		public static final int PIX_FMT_0RGB = 0x123 + 4;
		/** < packed RGB 8:8:8, 32bpp, RGB0RGB0... */
		public static final int PIX_FMT_RGB0 = (0x123 + 4 + 1);
		/** < packed BGR 8:8:8, 32bpp, 0BGR0BGR... */
		public static final int PIX_FMT_0BGR = (0x123 + 4 + 2);
		/** < packed BGR 8:8:8, 32bpp, BGR0BGR0... */
		public static final int PIX_FMT_BGR0 = (0x123 + 4 + 3);
		/** < planar YUV 4:4:4 32bpp, (1 Cr & Cb sample per 1x1 Y & A samples) */
		public static final int PIX_FMT_YUVA444P = (0x123 + 4 + 4);
		/** < planar YUV 4:2:2 24bpp, (1 Cr & Cb sample per 2x1 Y & A samples) */
		public static final int PIX_FMT_YUVA422P = (0x123 + 4 + 5);
		/** < planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int PIX_FMT_YUV420P12BE = (0x123 + 4 + 6);
		/** < planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int PIX_FMT_YUV420P12LE = (0x123 + 4 + 7);
		/** < planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian */
		public static final int PIX_FMT_YUV420P14BE = (0x123 + 4 + 8);
		/** < planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian */
		public static final int PIX_FMT_YUV420P14LE = (0x123 + 4 + 9);
		/** < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV422P12BE = (0x123 + 4 + 10);
		/** < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV422P12LE = (0x123 + 4 + 11);
		/** < planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV422P14BE = (0x123 + 4 + 12);
		/** < planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV422P14LE = (0x123 + 4 + 13);
		/** < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV444P12BE = (0x123 + 4 + 14);
		/** < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV444P12LE = (0x123 + 4 + 15);
		/** < planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian */
		public static final int PIX_FMT_YUV444P14BE = (0x123 + 4 + 16);
		/** < planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian */
		public static final int PIX_FMT_YUV444P14LE = (0x123 + 4 + 17);
		/** < planar GBR 4:4:4 36bpp, big endian */
		public static final int PIX_FMT_GBRP12BE = (0x123 + 4 + 18);
		/** < planar GBR 4:4:4 36bpp, little endian */
		public static final int PIX_FMT_GBRP12LE = (0x123 + 4 + 19);
		/** < planar GBR 4:4:4 42bpp, big endian */
		public static final int PIX_FMT_GBRP14BE = (0x123 + 4 + 20);
		/** < planar GBR 4:4:4 42bpp, little endian */
		public static final int PIX_FMT_GBRP14LE = (0x123 + 4 + 21);
		/** < number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions */
		public static final int PIX_FMT_NB = (0x123 + 4 + 22);
	};
	/**
	 * Audio Sample Formats<br>
	 * * @par<br>
	 * The data described by the sample format is always in native-endian order.<br>
	 * Sample values can be expressed by native C types, hence the lack of a signed<br>
	 * 24-bit sample format even though it is a common raw audio data format.<br>
	 * * @par<br>
	 * The floating-point formats are based on full volume being in the range<br>
	 * [-1.0, 1.0]. Any values outside this range are beyond full volume level.<br>
	 * * @par<br>
	 * The data layout as used in av_samples_fill_arrays() and elsewhere in FFmpeg<br>
	 * (such as AVFrame in libavcodec) is as follows:<br>
	 * * For planar sample formats, each audio channel is in a separate data plane,<br>
	 * and linesize is the buffer size, in bytes, for a single plane. All data<br>
	 * planes must be the same size. For packed sample formats, only the first data<br>
	 * plane is used, and samples for each channel are interleaved. In this case,<br>
	 * linesize is the buffer size, in bytes, for the 1 plane.<br>
	 * enum values
	 */
	public static interface AVSampleFormat {
		public static final int AV_SAMPLE_FMT_NONE = -1;
		/** < unsigned 8 bits */
		public static final int AV_SAMPLE_FMT_U8 = 0;
		/** < signed 16 bits */
		public static final int AV_SAMPLE_FMT_S16 = 1;
		/** < signed 32 bits */
		public static final int AV_SAMPLE_FMT_S32 = 2;
		/** < float */
		public static final int AV_SAMPLE_FMT_FLT = 3;
		/** < double */
		public static final int AV_SAMPLE_FMT_DBL = 4;
		/** < unsigned 8 bits, planar */
		public static final int AV_SAMPLE_FMT_U8P = 5;
		/** < signed 16 bits, planar */
		public static final int AV_SAMPLE_FMT_S16P = 6;
		/** < signed 32 bits, planar */
		public static final int AV_SAMPLE_FMT_S32P = 7;
		/** < float, planar */
		public static final int AV_SAMPLE_FMT_FLTP = 8;
		/** < double, planar */
		public static final int AV_SAMPLE_FMT_DBLP = 9;
		/** < Number of sample formats. DO NOT USE if linking dynamically */
		public static final int AV_SAMPLE_FMT_NB = 10;
	};
	/** enum values */
	public static interface AVFrameSideDataType {
		/** The data is the AVPanScan struct defined in libavcodec. */
		public static final int AV_FRAME_DATA_PANSCAN = 0;
	};
	/** < all automatic conversions enabled */
	public static final int AVFILTER_AUTO_CONVERT_ALL = 0;
	/** < all automatic conversions disabled */
	public static final int AVFILTER_AUTO_CONVERT_NONE = -1;
	public static final int AVERROR_MUXER_NOT_FOUND = (-((0xF8) | (('M') << 8) | (('U') << 16) | (('X') << 24)));
	public static final boolean FF_API_OLD_ENCODE_AUDIO = (55 < 56);
	public static final boolean FF_API_AVFILTER_OPEN = (3 < 4);
	public static final int AVERROR_FILTER_NOT_FOUND = (-((0xF8) | (('F') << 8) | (('I') << 16) | (('L') << 24)));
	public static final int AVFILTER_FLAG_DYNAMIC_INPUTS = (1 << 0);
	public static final int AVERROR_EXTERNAL = (-(('E') | (('X') << 8) | (('T') << 16) | ((' ') << 24)));
	public static final int AV_HAVE_INCOMPATIBLE_FORK_ABI = 0;
	public static final int AVERROR_UNKNOWN = (-(('U') | (('N') << 8) | (('K') << 16) | (('N') << 24)));
	public static final boolean FF_API_CONTEXT_SIZE = (52 < 53);
	public static final int LIBAVUTIL_VERSION_INT = (52 << 16 | 38 << 8 | 100);
	public static final int AVERROR_DEMUXER_NOT_FOUND = (-((0xF8) | (('D') << 8) | (('E') << 16) | (('M') << 24)));
	public static final int LIBAVFILTER_VERSION_MAJOR = 3;
	public static final int AVFILTER_THREAD_SLICE = (1 << 0);
	public static final boolean FF_API_OLD_AVOPTIONS = (52 < 53);
	public static final boolean FF_API_OLD_ENCODE_VIDEO = (55 < 56);
	public static final int AV_PERM_PRESERVE = 0x04;
	public static final boolean FF_API_SAMPLES_UTILS_RETURN_ZERO = (52 < 53);
	public static final boolean FF_API_PIX_FMT_DESC = (52 < 53);
	public static final boolean FF_API_MISSING_SAMPLE = (55 < 56);
	public static final String LIBAVFILTER_IDENT = "Lavfi";
	public static final int AVERROR_OPTION_NOT_FOUND = (-((0xF8) | (('O') << 8) | (('P') << 16) | (('T') << 24)));
	public static final int FF_LAMBDA_SCALE = (1 << 7);
	public static final int LIBAVCODEC_VERSION_MINOR = 18;
	public static final int AVFILTER_FLAG_SUPPORT_TIMELINE = ((1 << 16) | (1 << 17));
	public static final int AV_HAVE_BIGENDIAN = 0;
	public static final int AV_DICT_DONT_STRDUP_KEY = 4;
	public static final int AV_DICT_IGNORE_SUFFIX = 2;
	public static final int AVERROR_BUG2 = (-(('B') | (('U') << 8) | (('G') << 16) | ((' ') << 24)));
	public static final boolean FF_API_PIX_FMT = (52 < 53);
	public static final int LIBAVFILTER_VERSION_MICRO = 101;
	public static final int LIBAVFILTER_VERSION_INT = (3 << 16 | 79 << 8 | 101);
	public static final int AV_LOG_DEBUG = 48;
	public static final int AVPALETTE_SIZE = 1024;
	public static final boolean FF_API_AV_REVERSE = (52 < 53);
	public static final double M_LOG2_10 = 3.32192809488736234787;
	public static final int FF_DECODE_ERROR_INVALID_BITSTREAM = 1;
	public static final int AV_LOG_MAX_OFFSET = (48 - -8);
	public static final boolean FF_API_DEINTERLACE = (55 < 56);
	public static final int AV_LOG_WARNING = 24;
	public static final int FF_QP2LAMBDA = 118;
	public static final int LIBAVCODEC_BUILD = (55 << 16 | 18 << 8 | 102);
	public static final int AV_DICT_APPEND = 32;
	public static final int AVERROR_PROTOCOL_NOT_FOUND = (-((0xF8) | (('P') << 8) | (('R') << 16) | (('O') << 24)));
	public static final int AVFILTER_CMD_FLAG_FAST = 2;
	public static final int AV_HAVE_INCOMPATIBLE_LIBAV_ABI = 0;
	public static final boolean FF_API_DESTRUCT_PACKET = (55 < 56);
	public static final int LIBAVCODEC_VERSION_INT = (55 << 16 | 18 << 8 | 102);
	public static final int LIBAVCODEC_VERSION_MAJOR = 55;
	public static final int AVFILTER_ALIGN = 16;
	public static final boolean FF_API_LOWRES = (55 < 56);
	public static final int AV_NUM_DATA_POINTERS = 8;
	public static final int FF_LAMBDA_MAX = (256 * 128 - 1);
	public static final int AV_ERROR_MAX_STRING_SIZE = 64;
	public static final String LIBAVCODEC_IDENT = "Lavc";
	public static final boolean FF_API_ACONVERT_FILTER = (3 < 4);
	public static final int AVERROR_EXIT = (-(('E') | (('X') << 8) | (('I') << 16) | (('T') << 24)));
	public static final int AV_PERM_ALIGN = 0x40;
	public static final int AV_LOG_VERBOSE = 40;
	public static final int AVERROR_EXPERIMENTAL = (0x2bb2afa8);
	public static final boolean FF_API_AVFRAME_LAVC = (52 < 53);
	public static final int AV_LOG_ERROR = 16;
	public static final boolean FF_API_AVFILTERPAD_PUBLIC = (3 < 4);
	public static final int AV_PERM_WRITE = 0x02;
	public static final int LIBAVUTIL_BUILD = (52 << 16 | 38 << 8 | 100);
	public static final int FF_QUALITY_SCALE = (1 << 7);
	public static final int AV_LOG_INFO = 32;
	public static final int AV_TIME_BASE = 1000000;
	public static final boolean FF_API_CODEC_ID = (55 < 56);
	public static final boolean FF_API_OLD_FILTER_OPTS = (3 < 4);
	public static final boolean FF_API_CPU_FLAG_MMX2 = (52 < 53);
	public static final int AVFILTER_FLAG_SLICE_THREADS = (1 << 2);
	public static final boolean FF_API_FILL_FRAME = (3 < 4);
	public static final int AVERROR_BSF_NOT_FOUND = (-((0xF8) | (('B') << 8) | (('S') << 16) | (('F') << 24)));
	public static final boolean FF_API_GET_BUFFER = (55 < 56);
	public static final int FF_DECODE_ERROR_MISSING_REFERENCE = 2;
	public static final int AVERROR_PATCHWELCOME = (-(('P') | (('A') << 8) | (('W') << 16) | (('E') << 24)));
	public static final boolean FF_API_AVCODEC_RESAMPLE = (55 < 56);
	public static final int AV_PERM_REUSE2 = 0x10;
	public static final int AV_DICT_MATCH_CASE = 1;
	public static final boolean FF_API_GET_BITS_PER_SAMPLE_FMT = (52 < 53);
	public static final int AVERROR_DECODER_NOT_FOUND = (-((0xF8) | (('D') << 8) | (('E') << 16) | (('C') << 24)));
	public static final boolean FF_API_OLD_TIMECODE = (55 < 55);
	public static final int AVFILTER_FLAG_DYNAMIC_OUTPUTS = (1 << 1);
	public static final int AV_LOG_FATAL = 8;
	public static final int AV_DICT_DONT_STRDUP_VAL = 8;
	public static final int LIBAVUTIL_VERSION_MICRO = 100;
	public static final int AV_LOG_SKIP_REPEATED = 1;
	public static final int AVERROR_STREAM_NOT_FOUND = (-((0xF8) | (('S') << 8) | (('T') << 16) | (('R') << 24)));
	public static final int AV_LOG_QUIET = -8;
	public static final int AVFILTER_FLAG_SUPPORT_TIMELINE_INTERNAL = (1 << 17);
	public static final boolean FF_API_OLD_DECODE_AUDIO = (55 < 56);
	public static final int LIBAVUTIL_VERSION_MINOR = 38;
	public static final int AV_DICT_DONT_OVERWRITE = 16;
	public static final boolean FF_API_AVFILTER_INIT_FILTER = (3 < 4);
	public static final int AVERROR_BUG = (-(('B') | (('U') << 8) | (('G') << 16) | (('!') << 24)));
	public static final int AV_PERM_NEG_LINESIZES = 0x20;
	public static final boolean FF_API_OLD_FILTER_REGISTER = (3 < 4);
	public static final boolean FF_API_ALLOC_CONTEXT = (55 < 55);
	public static final boolean FF_API_OLD_GRAPH_PARSE = (3 < 4);
	public static final boolean FF_API_AVFILTERBUFFER = (3 < 4);
	public static final boolean FF_API_AUDIOCONVERT = (52 < 53);
	public static final int AV_PERM_REUSE = 0x08;
	public static final String LIBAVUTIL_IDENT = "Lavu";
	public static final int LIBAVUTIL_VERSION_MAJOR = 52;
	public static final int LIBAVFILTER_VERSION_MINOR = 79;
	public static final int AV_PERM_READ = 0x01;
	public static final int AVERROR_ENCODER_NOT_FOUND = (-((0xF8) | (('E') << 8) | (('N') << 16) | (('C') << 24)));
	public static final int AVERROR_BUFFER_TOO_SMALL = (-(('B') | (('U') << 8) | (('F') << 16) | (('S') << 24)));
	public static final int LIBAVFILTER_BUILD = (3 << 16 | 79 << 8 | 101);
	public static final boolean FF_API_FOO_COUNT = (3 < 4);
	public static final int FF_LAMBDA_SHIFT = 7;
	public static final int AV_BUFFER_FLAG_READONLY = (1 << 0);
	public static final boolean FF_API_BUFFERSRC_BUFFER = (3 < 4);
	public static final int AV_HAVE_FAST_UNALIGNED = 1;
	public static final int AVFILTER_FLAG_SUPPORT_TIMELINE_GENERIC = (1 << 16);
	public static final boolean FF_API_AVCODEC_OPEN = (55 < 55);
	public static final boolean FF_API_FIND_OPT = (52 < 53);
	public static final int AVERROR_EOF = (-(('E') | (('O') << 8) | (('F') << 16) | ((' ') << 24)));
	public static final int AVERROR_INVALIDDATA = (-(('I') | (('N') << 8) | (('D') << 16) | (('A') << 24)));
	public static final double M_PHI = 1.61803398874989484820;
	public static final int AVPALETTE_COUNT = 256;
	public static final boolean FF_API_REQUEST_CHANNELS = (55 < 56);
	public static final int __STDC_HOSTED__ = 1;
	public static final int AV_LOG_PANIC = 0;
	public static final int LIBAVCODEC_VERSION_MICRO = 102;
	public static final boolean FF_API_LLS_PRIVATE = (52 < 53);
	public static final int AVFILTER_CMD_FLAG_ONE = 1;
	public interface av_log_set_callback_arg1_callback extends Callback {
		void apply(Pointer voidPtr1, int int1, Pointer charPtr1, LibavfilterLibrary.va_list va_list1);
	};
	public interface av_buffer_create_free_callback extends Callback {
		void apply(Pointer opaque, Pointer data);
	};
	public interface av_buffer_pool_init_alloc_callback extends Callback {
		AVBufferRef apply(int size);
	};
	/**
	 * Return the LIBAVUTIL_VERSION_INT constant.<br>
	 * Original signature : <code>int avutil_version()</code>
	 */
	int avutil_version();
	/**
	 * Return the libavutil build-time configuration.<br>
	 * Original signature : <code>char* avutil_configuration()</code>
	 */
	String avutil_configuration();
	/**
	 * Return the libavutil license.<br>
	 * Original signature : <code>char* avutil_license()</code>
	 */
	String avutil_license();
	/**
	 * Return a string describing the media_type enum, NULL if media_type<br>
	 * is unknown.<br>
	 * Original signature : <code>char* av_get_media_type_string(AVMediaType)</code>
	 */
	String av_get_media_type_string(int media_type);
	/**
	 * Return a single letter to describe the given picture type<br>
	 * pict_type.<br>
	 * * @param[in] pict_type the picture type @return a single character<br>
	 * representing the picture type, '?' if pict_type is unknown<br>
	 * Original signature : <code>char av_get_picture_type_char(AVPictureType)</code>
	 */
	byte av_get_picture_type_char(int pict_type);
	/** Original signature : <code>int av_log2(unsigned)</code> */
	int av_log2(int v);
	/** Original signature : <code>int av_log2_16bit(unsigned)</code> */
	int av_log2_16bit(int v);
	/**
	 * Put a description of the AVERROR code errnum in errbuf.<br>
	 * In case of failure the global variable errno is set to indicate the<br>
	 * error. Even in case of failure av_strerror() will print a generic<br>
	 * error message indicating the errnum provided to errbuf.<br>
	 * * @param errnum      error code to describe<br>
	 * @param errbuf      buffer to which description is written<br>
	 * @param errbuf_size the size in bytes of errbuf<br>
	 * @return 0 on success, a negative value if a description for errnum<br>
	 * cannot be found<br>
	 * Original signature : <code>int av_strerror(int, char*, size_t)</code><br>
	 * @deprecated use the safer methods {@link #av_strerror(int, java.nio.ByteBuffer, com.ochafik.lang.jnaerator.runtime.NativeSize)} and {@link #av_strerror(int, com.sun.jna.Pointer, com.ochafik.lang.jnaerator.runtime.NativeSize)} instead
	 */
	@Deprecated 
	int av_strerror(int errnum, Pointer errbuf, NativeSize errbuf_size);
	/**
	 * Put a description of the AVERROR code errnum in errbuf.<br>
	 * In case of failure the global variable errno is set to indicate the<br>
	 * error. Even in case of failure av_strerror() will print a generic<br>
	 * error message indicating the errnum provided to errbuf.<br>
	 * * @param errnum      error code to describe<br>
	 * @param errbuf      buffer to which description is written<br>
	 * @param errbuf_size the size in bytes of errbuf<br>
	 * @return 0 on success, a negative value if a description for errnum<br>
	 * cannot be found<br>
	 * Original signature : <code>int av_strerror(int, char*, size_t)</code>
	 */
	int av_strerror(int errnum, ByteBuffer errbuf, NativeSize errbuf_size);
	/**
	 * Allocate a block of size bytes with alignment suitable for all<br>
	 * memory accesses (including vectors if available on the CPU).<br>
	 * @param size Size in bytes for the memory block to be allocated.<br>
	 * @return Pointer to the allocated block, NULL if the block cannot<br>
	 * be allocated.<br>
	 * @see av_mallocz()<br>
	 * Original signature : <code>void* av_malloc(size_t)</code>
	 */
	Pointer av_malloc(NativeSize size);
	/**
	 * Allocate or reallocate a block of memory.<br>
	 * If ptr is NULL and size > 0, allocate a new block. If<br>
	 * size is zero, free the memory block pointed to by ptr.<br>
	 * @param ptr Pointer to a memory block already allocated with<br>
	 * av_malloc(z)() or av_realloc() or NULL.<br>
	 * @param size Size in bytes for the memory block to be allocated or<br>
	 * reallocated.<br>
	 * @return Pointer to a newly reallocated block or NULL if the block<br>
	 * cannot be reallocated or the function is used to free the memory block.<br>
	 * @see av_fast_realloc()<br>
	 * Original signature : <code>void* av_realloc(void*, size_t)</code>
	 */
	Pointer av_realloc(Pointer ptr, NativeSize size);
	/**
	 * Allocate or reallocate a block of memory.<br>
	 * This function does the same thing as av_realloc, except:<br>
	 * - It takes two arguments and checks the result of the multiplication for<br>
	 *   integer overflow.<br>
	 * - It frees the input block in case of failure, thus avoiding the memory<br>
	 *   leak with the classic "buf = realloc(buf); if (!buf) return -1;".<br>
	 * Original signature : <code>void* av_realloc_f(void*, size_t, size_t)</code>
	 */
	Pointer av_realloc_f(Pointer ptr, NativeSize nelem, NativeSize elsize);
	/**
	 * Allocate or reallocate an array.<br>
	 * If ptr is NULL and nmemb > 0, allocate a new block. If<br>
	 * nmemb is zero, free the memory block pointed to by ptr.<br>
	 * @param ptr Pointer to a memory block already allocated with<br>
	 * av_malloc(z)() or av_realloc() or NULL.<br>
	 * @param nmemb Number of elements<br>
	 * @param size Size of the single element<br>
	 * @return Pointer to a newly reallocated block or NULL if the block<br>
	 * cannot be reallocated or the function is used to free the memory block.<br>
	 * Original signature : <code>void* av_realloc_array(void*, size_t, size_t)</code>
	 */
	Pointer av_realloc_array(Pointer ptr, NativeSize nmemb, NativeSize size);
	/**
	 * Allocate or reallocate an array.<br>
	 * If *ptr is NULL and nmemb > 0, allocate a new block. If<br>
	 * nmemb is zero, free the memory block pointed to by ptr.<br>
	 * @param ptr Pointer to a pointer to a memory block already allocated<br>
	 * with av_malloc(z)() or av_realloc(), or pointer to a pointer to NULL.<br>
	 * The pointer is updated on success, or freed on failure.<br>
	 * @param nmemb Number of elements<br>
	 * @param size Size of the single element<br>
	 * @return Zero on success, an AVERROR error code on failure.<br>
	 * Original signature : <code>int av_reallocp_array(void*, size_t, size_t)</code>
	 */
	int av_reallocp_array(Pointer ptr, NativeSize nmemb, NativeSize size);
	/**
	 * Free a memory block which has been allocated with av_malloc(z)() or<br>
	 * av_realloc().<br>
	 * @param ptr Pointer to the memory block which should be freed.<br>
	 * @note ptr = NULL is explicitly allowed.<br>
	 * @note It is recommended that you use av_freep() instead.<br>
	 * @see av_freep()<br>
	 * Original signature : <code>void av_free(void*)</code>
	 */
	void av_free(Pointer ptr);
	/**
	 * Allocate a block of size bytes with alignment suitable for all<br>
	 * memory accesses (including vectors if available on the CPU) and<br>
	 * zero all the bytes of the block.<br>
	 * @param size Size in bytes for the memory block to be allocated.<br>
	 * @return Pointer to the allocated block, NULL if it cannot be allocated.<br>
	 * @see av_malloc()<br>
	 * Original signature : <code>void* av_mallocz(size_t)</code>
	 */
	Pointer av_mallocz(NativeSize size);
	/**
	 * Allocate a block of nmemb * size bytes with alignment suitable for all<br>
	 * memory accesses (including vectors if available on the CPU) and<br>
	 * zero all the bytes of the block.<br>
	 * The allocation will fail if nmemb * size is greater than or equal<br>
	 * to INT_MAX.<br>
	 * @param nmemb<br>
	 * @param size<br>
	 * @return Pointer to the allocated block, NULL if it cannot be allocated.<br>
	 * Original signature : <code>void* av_calloc(size_t, size_t)</code>
	 */
	Pointer av_calloc(NativeSize nmemb, NativeSize size);
	/**
	 * Duplicate the string s.<br>
	 * @param s string to be duplicated<br>
	 * @return Pointer to a newly allocated string containing a<br>
	 * copy of s or NULL if the string cannot be allocated.<br>
	 * Original signature : <code>char* av_strdup(const char*)</code><br>
	 * @deprecated use the safer methods {@link #av_strdup(java.lang.String)} and {@link #av_strdup(com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	Pointer av_strdup(Pointer s);
	/**
	 * Duplicate the string s.<br>
	 * @param s string to be duplicated<br>
	 * @return Pointer to a newly allocated string containing a<br>
	 * copy of s or NULL if the string cannot be allocated.<br>
	 * Original signature : <code>char* av_strdup(const char*)</code>
	 */
	Pointer av_strdup(String s);
	/**
	 * Duplicate the buffer p.<br>
	 * @param p buffer to be duplicated<br>
	 * @return Pointer to a newly allocated buffer containing a<br>
	 * copy of p or NULL if the buffer cannot be allocated.<br>
	 * Original signature : <code>void* av_memdup(const void*, size_t)</code>
	 */
	Pointer av_memdup(Pointer p, NativeSize size);
	/**
	 * Free a memory block which has been allocated with av_malloc(z)() or<br>
	 * av_realloc() and set the pointer pointing to it to NULL.<br>
	 * @param ptr Pointer to the pointer to the memory block which should<br>
	 * be freed.<br>
	 * @see av_free()<br>
	 * Original signature : <code>void av_freep(void*)</code>
	 */
	void av_freep(Pointer ptr);
	/**
	 * Add an element to a dynamic array.<br>
	 * * The array to grow is supposed to be an array of pointers to<br>
	 * structures, and the element to add must be a pointer to an already<br>
	 * allocated structure.<br>
	 * * The array is reallocated when its size reaches powers of 2.<br>
	 * Therefore, the amortized cost of adding an element is constant.<br>
	 * * In case of success, the pointer to the array is updated in order to<br>
	 * point to the new grown array, and the number pointed to by nb_ptr<br>
	 * is incremented.<br>
	 * In case of failure, the array is freed, *tab_ptr is set to NULL and<br>
	 * *nb_ptr is set to 0.<br>
	 * * @param tab_ptr pointer to the array to grow<br>
	 * @param nb_ptr  pointer to the number of elements in the array<br>
	 * @param elem    element to add<br>
	 * @see av_dynarray2_add()<br>
	 * Original signature : <code>void av_dynarray_add(void*, int*, void*)</code><br>
	 * @deprecated use the safer methods {@link #av_dynarray_add(com.sun.jna.Pointer, java.nio.IntBuffer, com.sun.jna.Pointer)} and {@link #av_dynarray_add(com.sun.jna.Pointer, com.sun.jna.ptr.IntByReference, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	void av_dynarray_add(Pointer tab_ptr, IntByReference nb_ptr, Pointer elem);
	/**
	 * Add an element to a dynamic array.<br>
	 * * The array to grow is supposed to be an array of pointers to<br>
	 * structures, and the element to add must be a pointer to an already<br>
	 * allocated structure.<br>
	 * * The array is reallocated when its size reaches powers of 2.<br>
	 * Therefore, the amortized cost of adding an element is constant.<br>
	 * * In case of success, the pointer to the array is updated in order to<br>
	 * point to the new grown array, and the number pointed to by nb_ptr<br>
	 * is incremented.<br>
	 * In case of failure, the array is freed, *tab_ptr is set to NULL and<br>
	 * *nb_ptr is set to 0.<br>
	 * * @param tab_ptr pointer to the array to grow<br>
	 * @param nb_ptr  pointer to the number of elements in the array<br>
	 * @param elem    element to add<br>
	 * @see av_dynarray2_add()<br>
	 * Original signature : <code>void av_dynarray_add(void*, int*, void*)</code>
	 */
	void av_dynarray_add(Pointer tab_ptr, IntBuffer nb_ptr, Pointer elem);
	/**
	 * Add an element of size elem_size to a dynamic array.<br>
	 * * The array is reallocated when its number of elements reaches powers of 2.<br>
	 * Therefore, the amortized cost of adding an element is constant.<br>
	 * * In case of success, the pointer to the array is updated in order to<br>
	 * point to the new grown array, and the number pointed to by nb_ptr<br>
	 * is incremented.<br>
	 * In case of failure, the array is freed, *tab_ptr is set to NULL and<br>
	 * *nb_ptr is set to 0.<br>
	 * * @param tab_ptr   pointer to the array to grow<br>
	 * @param nb_ptr    pointer to the number of elements in the array<br>
	 * @param elem_size size in bytes of the elements in the array<br>
	 * @param elem_data pointer to the data of the element to add. If NULL, the space of<br>
	 *                  the new added element is not filled.<br>
	 * @return          pointer to the data of the element to copy in the new allocated space.<br>
	 *                  If NULL, the new allocated space is left uninitialized."<br>
	 * @see av_dynarray_add()<br>
	 * Original signature : <code>void* av_dynarray2_add(void**, int*, size_t, const uint8_t*)</code><br>
	 * @deprecated use the safer methods {@link #av_dynarray2_add(com.sun.jna.ptr.PointerByReference, java.nio.IntBuffer, com.ochafik.lang.jnaerator.runtime.NativeSize, java.nio.ByteBuffer)} and {@link #av_dynarray2_add(com.sun.jna.ptr.PointerByReference, com.sun.jna.ptr.IntByReference, com.ochafik.lang.jnaerator.runtime.NativeSize, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	Pointer av_dynarray2_add(PointerByReference tab_ptr, IntByReference nb_ptr, NativeSize elem_size, Pointer elem_data);
	/**
	 * Add an element of size elem_size to a dynamic array.<br>
	 * * The array is reallocated when its number of elements reaches powers of 2.<br>
	 * Therefore, the amortized cost of adding an element is constant.<br>
	 * * In case of success, the pointer to the array is updated in order to<br>
	 * point to the new grown array, and the number pointed to by nb_ptr<br>
	 * is incremented.<br>
	 * In case of failure, the array is freed, *tab_ptr is set to NULL and<br>
	 * *nb_ptr is set to 0.<br>
	 * * @param tab_ptr   pointer to the array to grow<br>
	 * @param nb_ptr    pointer to the number of elements in the array<br>
	 * @param elem_size size in bytes of the elements in the array<br>
	 * @param elem_data pointer to the data of the element to add. If NULL, the space of<br>
	 *                  the new added element is not filled.<br>
	 * @return          pointer to the data of the element to copy in the new allocated space.<br>
	 *                  If NULL, the new allocated space is left uninitialized."<br>
	 * @see av_dynarray_add()<br>
	 * Original signature : <code>void* av_dynarray2_add(void**, int*, size_t, const uint8_t*)</code>
	 */
	Pointer av_dynarray2_add(PointerByReference tab_ptr, IntBuffer nb_ptr, NativeSize elem_size, ByteBuffer elem_data);
	/**
	 * Set the maximum size that may me allocated in one block.<br>
	 * Original signature : <code>void av_max_alloc(size_t)</code>
	 */
	void av_max_alloc(NativeSize max);
	/**
	 * @brief deliberately overlapping memcpy implementation<br>
	 * @param dst destination buffer<br>
	 * @param back how many bytes back we start (the initial size of the overlapping window), must be > 0<br>
	 * @param cnt number of bytes to copy, must be >= 0<br>
	 * * cnt > back is valid, this will copy the bytes we just copied,<br>
	 * thus creating a repeating pattern with a period length of back.<br>
	 * Original signature : <code>void av_memcpy_backptr(uint8_t*, int, int)</code><br>
	 * @deprecated use the safer methods {@link #av_memcpy_backptr(java.nio.ByteBuffer, int, int)} and {@link #av_memcpy_backptr(com.sun.jna.Pointer, int, int)} instead
	 */
	@Deprecated 
	void av_memcpy_backptr(Pointer dst, int back, int cnt);
	/**
	 * @brief deliberately overlapping memcpy implementation<br>
	 * @param dst destination buffer<br>
	 * @param back how many bytes back we start (the initial size of the overlapping window), must be > 0<br>
	 * @param cnt number of bytes to copy, must be >= 0<br>
	 * * cnt > back is valid, this will copy the bytes we just copied,<br>
	 * thus creating a repeating pattern with a period length of back.<br>
	 * Original signature : <code>void av_memcpy_backptr(uint8_t*, int, int)</code>
	 */
	void av_memcpy_backptr(ByteBuffer dst, int back, int cnt);
	/**
	 * Reduce a fraction.<br>
	 * This is useful for framerate calculations.<br>
	 * @param dst_num destination numerator<br>
	 * @param dst_den destination denominator<br>
	 * @param num source numerator<br>
	 * @param den source denominator<br>
	 * @param max the maximum allowed for dst_num & dst_den<br>
	 * @return 1 if exact, 0 otherwise<br>
	 * Original signature : <code>int av_reduce(int*, int*, int64_t, int64_t, int64_t)</code><br>
	 * @deprecated use the safer methods {@link #av_reduce(java.nio.IntBuffer, java.nio.IntBuffer, long, long, long)} and {@link #av_reduce(com.sun.jna.ptr.IntByReference, com.sun.jna.ptr.IntByReference, long, long, long)} instead
	 */
	@Deprecated 
	int av_reduce(IntByReference dst_num, IntByReference dst_den, long num, long den, long max);
	/**
	 * Reduce a fraction.<br>
	 * This is useful for framerate calculations.<br>
	 * @param dst_num destination numerator<br>
	 * @param dst_den destination denominator<br>
	 * @param num source numerator<br>
	 * @param den source denominator<br>
	 * @param max the maximum allowed for dst_num & dst_den<br>
	 * @return 1 if exact, 0 otherwise<br>
	 * Original signature : <code>int av_reduce(int*, int*, int64_t, int64_t, int64_t)</code>
	 */
	int av_reduce(IntBuffer dst_num, IntBuffer dst_den, long num, long den, long max);
	/**
	 * Multiply two rationals.<br>
	 * @param b first rational<br>
	 * @param c second rational<br>
	 * @return b*c<br>
	 * Original signature : <code>AVRational av_mul_q(AVRational, AVRational)</code>
	 */
	AVRational.ByValue av_mul_q(AVRational.ByValue b, AVRational.ByValue c);
	/**
	 * Divide one rational by another.<br>
	 * @param b first rational<br>
	 * @param c second rational<br>
	 * @return b/c<br>
	 * Original signature : <code>AVRational av_div_q(AVRational, AVRational)</code>
	 */
	AVRational.ByValue av_div_q(AVRational.ByValue b, AVRational.ByValue c);
	/**
	 * Add two rationals.<br>
	 * @param b first rational<br>
	 * @param c second rational<br>
	 * @return b+c<br>
	 * Original signature : <code>AVRational av_add_q(AVRational, AVRational)</code>
	 */
	AVRational.ByValue av_add_q(AVRational.ByValue b, AVRational.ByValue c);
	/**
	 * Subtract one rational from another.<br>
	 * @param b first rational<br>
	 * @param c second rational<br>
	 * @return b-c<br>
	 * Original signature : <code>AVRational av_sub_q(AVRational, AVRational)</code>
	 */
	AVRational.ByValue av_sub_q(AVRational.ByValue b, AVRational.ByValue c);
	/**
	 * Convert a double precision floating point number to a rational.<br>
	 * inf is expressed as {1,0} or {-1,0} depending on the sign.<br>
	 * * @param d double to convert<br>
	 * @param max the maximum allowed numerator and denominator<br>
	 * @return (AVRational) d<br>
	 * Original signature : <code>AVRational av_d2q(double, int)</code>
	 */
	AVRational.ByValue av_d2q(double d, int max);
	/**
	 * @return 1 if q1 is nearer to q than q2, -1 if q2 is nearer<br>
	 * than q1, 0 if they have the same distance.<br>
	 * Original signature : <code>int av_nearer_q(AVRational, AVRational, AVRational)</code>
	 */
	int av_nearer_q(AVRational.ByValue q, AVRational.ByValue q1, AVRational.ByValue q2);
	/**
	 * Find the nearest value in q_list to q.<br>
	 * @param q_list an array of rationals terminated by {0, 0}<br>
	 * @return the index of the nearest value found in the array<br>
	 * Original signature : <code>int av_find_nearest_q_idx(AVRational, const AVRational*)</code>
	 */
	int av_find_nearest_q_idx(AVRational.ByValue q, AVRational q_list);
	/**
	 * Return the greatest common divisor of a and b.<br>
	 * If both a and b are 0 or either or both are <0 then behavior is<br>
	 * undefined.<br>
	 * Original signature : <code>int64_t av_gcd(int64_t, int64_t)</code>
	 */
	long av_gcd(long a, long b);
	/**
	 * Rescale a 64-bit integer with rounding to nearest.<br>
	 * A simple a*b/c isn't possible as it can overflow.<br>
	 * Original signature : <code>int64_t av_rescale(int64_t, int64_t, int64_t)</code>
	 */
	long av_rescale(long a, long b, long c);
	/**
	 * Rescale a 64-bit integer with specified rounding.<br>
	 * A simple a*b/c isn't possible as it can overflow.<br>
	 * * @return rescaled value a, or if AV_ROUND_PASS_MINMAX is set and a is<br>
	 *         INT64_MIN or INT64_MAX then a is passed through unchanged.<br>
	 * Original signature : <code>int64_t av_rescale_rnd(int64_t, int64_t, int64_t, AVRounding)</code>
	 */
	long av_rescale_rnd(long a, long b, long c, int arg1);
	/**
	 * Rescale a 64-bit integer by 2 rational numbers.<br>
	 * Original signature : <code>int64_t av_rescale_q(int64_t, AVRational, AVRational)</code>
	 */
	long av_rescale_q(long a, AVRational.ByValue bq, AVRational.ByValue cq);
	/**
	 * Rescale a 64-bit integer by 2 rational numbers with specified rounding.<br>
	 * * @return rescaled value a, or if AV_ROUND_PASS_MINMAX is set and a is<br>
	 *         INT64_MIN or INT64_MAX then a is passed through unchanged.<br>
	 * Original signature : <code>int64_t av_rescale_q_rnd(int64_t, AVRational, AVRational, AVRounding)</code>
	 */
	long av_rescale_q_rnd(long a, AVRational.ByValue bq, AVRational.ByValue cq, int arg1);
	/**
	 * Compare 2 timestamps each in its own timebases.<br>
	 * The result of the function is undefined if one of the timestamps<br>
	 * is outside the int64_t range when represented in the others timebase.<br>
	 * @return -1 if ts_a is before ts_b, 1 if ts_a is after ts_b or 0 if they represent the same position<br>
	 * Original signature : <code>int av_compare_ts(int64_t, AVRational, int64_t, AVRational)</code>
	 */
	int av_compare_ts(long ts_a, AVRational.ByValue tb_a, long ts_b, AVRational.ByValue tb_b);
	/**
	 * Compare 2 integers modulo mod.<br>
	 * That is we compare integers a and b for which only the least<br>
	 * significant log2(mod) bits are known.<br>
	 * * @param mod must be a power of 2<br>
	 * @return a negative value if a is smaller than b<br>
	 *         a positive value if a is greater than b<br>
	 *         0                if a equals          b<br>
	 * Original signature : <code>int64_t av_compare_mod(uint64_t, uint64_t, uint64_t)</code>
	 */
	long av_compare_mod(long a, long b, long mod);
	/**
	 * Rescale a timestamp while preserving known durations.<br>
	 * * @param in_ts Input timestamp<br>
	 * @param in_tb Input timesbase<br>
	 * @param fs_tb Duration and *last timebase<br>
	 * @param duration duration till the next call<br>
	 * @param out_tb Output timesbase<br>
	 * Original signature : <code>int64_t av_rescale_delta(AVRational, int64_t, AVRational, int, int64_t*, AVRational)</code><br>
	 * @deprecated use the safer methods {@link #av_rescale_delta(org.javaavc.gen.avfilter.AVRational.ByValue, long, org.javaavc.gen.avfilter.AVRational.ByValue, int, java.nio.LongBuffer, org.javaavc.gen.avfilter.AVRational.ByValue)} and {@link #av_rescale_delta(org.javaavc.gen.avfilter.AVRational.ByValue, long, org.javaavc.gen.avfilter.AVRational.ByValue, int, com.sun.jna.ptr.LongByReference, org.javaavc.gen.avfilter.AVRational.ByValue)} instead
	 */
	@Deprecated 
	long av_rescale_delta(AVRational.ByValue in_tb, long in_ts, AVRational.ByValue fs_tb, int duration, LongByReference last, AVRational.ByValue out_tb);
	/**
	 * Rescale a timestamp while preserving known durations.<br>
	 * * @param in_ts Input timestamp<br>
	 * @param in_tb Input timesbase<br>
	 * @param fs_tb Duration and *last timebase<br>
	 * @param duration duration till the next call<br>
	 * @param out_tb Output timesbase<br>
	 * Original signature : <code>int64_t av_rescale_delta(AVRational, int64_t, AVRational, int, int64_t*, AVRational)</code>
	 */
	long av_rescale_delta(AVRational.ByValue in_tb, long in_ts, AVRational.ByValue fs_tb, int duration, LongBuffer last, AVRational.ByValue out_tb);
	/** Original signature : <code>double av_int2dbl(int64_t)</code> */
	double av_int2dbl(long v);
	/** Original signature : <code>float av_int2flt(int32_t)</code> */
	float av_int2flt(int v);
	/** Original signature : <code>double av_ext2dbl(const AVExtFloat)</code> */
	double av_ext2dbl(org.javaavc.gen.avfilter.AVExtFloat.ByValue ext);
	/** Original signature : <code>int64_t av_dbl2int(double)</code> */
	long av_dbl2int(double d);
	/** Original signature : <code>int32_t av_flt2int(float)</code> */
	int av_flt2int(float d);
	/** Original signature : <code>AVExtFloat av_dbl2ext(double)</code> */
	org.javaavc.gen.avfilter.AVExtFloat.ByValue av_dbl2ext(double d);
	/**
	 * Send the specified message to the log if the level is less than or equal<br>
	 * to the current av_log_level. By default, all logging messages are sent to<br>
	 * stderr. This behavior can be altered by setting a different av_vlog callback<br>
	 * function.<br>
	 * * @param avcl A pointer to an arbitrary struct of which the first field is a<br>
	 * pointer to an AVClass struct.<br>
	 * @param level The importance level of the message, lower values signifying<br>
	 * higher importance.<br>
	 * @param fmt The format string (printf-compatible) that specifies how<br>
	 * subsequent arguments are converted to output.<br>
	 * @see av_vlog<br>
	 * Original signature : <code>void av_log(void*, int, const char*, null)</code><br>
	 * @deprecated use the safer methods {@link #av_log(com.sun.jna.Pointer, int, java.lang.String, java.lang.Object)} and {@link #av_log(com.sun.jna.Pointer, int, com.sun.jna.Pointer, java.lang.Object)} instead
	 */
	@Deprecated 
	void av_log(Pointer avcl, int level, Pointer fmt, Object... varargs);
	/**
	 * Send the specified message to the log if the level is less than or equal<br>
	 * to the current av_log_level. By default, all logging messages are sent to<br>
	 * stderr. This behavior can be altered by setting a different av_vlog callback<br>
	 * function.<br>
	 * * @param avcl A pointer to an arbitrary struct of which the first field is a<br>
	 * pointer to an AVClass struct.<br>
	 * @param level The importance level of the message, lower values signifying<br>
	 * higher importance.<br>
	 * @param fmt The format string (printf-compatible) that specifies how<br>
	 * subsequent arguments are converted to output.<br>
	 * @see av_vlog<br>
	 * Original signature : <code>void av_log(void*, int, const char*, null)</code>
	 */
	void av_log(Pointer avcl, int level, String fmt, Object... varargs);
	/**
	 * Original signature : <code>void av_vlog(void*, int, const char*, va_list)</code><br>
	 * @deprecated use the safer methods {@link #av_vlog(com.sun.jna.Pointer, int, java.lang.String, org.javaavc.gen.avfilter.LibavfilterLibrary.va_list)} and {@link #av_vlog(com.sun.jna.Pointer, int, com.sun.jna.Pointer, org.javaavc.gen.avfilter.LibavfilterLibrary.va_list)} instead
	 */
	@Deprecated 
	void av_vlog(Pointer avcl, int level, Pointer fmt, LibavfilterLibrary.va_list va_list1);
	/** Original signature : <code>void av_vlog(void*, int, const char*, va_list)</code> */
	void av_vlog(Pointer avcl, int level, String fmt, LibavfilterLibrary.va_list va_list1);
	/** Original signature : <code>int av_log_get_level()</code> */
	int av_log_get_level();
	/** Original signature : <code>void av_log_set_level(int)</code> */
	void av_log_set_level(int int1);
	/** Original signature : <code>void av_log_set_callback(av_log_set_callback_arg1_callback*)</code> */
	void av_log_set_callback(LibavfilterLibrary.av_log_set_callback_arg1_callback arg1);
	/**
	 * Original signature : <code>void av_log_default_callback(void*, int, const char*, va_list)</code><br>
	 * @deprecated use the safer methods {@link #av_log_default_callback(com.sun.jna.Pointer, int, java.lang.String, org.javaavc.gen.avfilter.LibavfilterLibrary.va_list)} and {@link #av_log_default_callback(com.sun.jna.Pointer, int, com.sun.jna.Pointer, org.javaavc.gen.avfilter.LibavfilterLibrary.va_list)} instead
	 */
	@Deprecated 
	void av_log_default_callback(Pointer ptr, int level, Pointer fmt, LibavfilterLibrary.va_list vl);
	/** Original signature : <code>void av_log_default_callback(void*, int, const char*, va_list)</code> */
	void av_log_default_callback(Pointer ptr, int level, String fmt, LibavfilterLibrary.va_list vl);
	/** Original signature : <code>char* av_default_item_name(void*)</code> */
	String av_default_item_name(Pointer ctx);
	/** Original signature : <code>AVClassCategory av_default_get_category(void*)</code> */
	int av_default_get_category(Pointer ptr);
	/**
	 * Format a line of log the same way as the default callback.<br>
	 * @param line          buffer to receive the formated line<br>
	 * @param line_size     size of the buffer<br>
	 * @param print_prefix  used to store whether the prefix must be printed;<br>
	 *                      must point to a persistent integer initially set to 1<br>
	 * Original signature : <code>void av_log_format_line(void*, int, const char*, va_list, char*, int, int*)</code><br>
	 * @deprecated use the safer methods {@link #av_log_format_line(com.sun.jna.Pointer, int, java.lang.String, org.javaavc.gen.avfilter.LibavfilterLibrary.va_list, java.nio.ByteBuffer, int, java.nio.IntBuffer)} and {@link #av_log_format_line(com.sun.jna.Pointer, int, com.sun.jna.Pointer, org.javaavc.gen.avfilter.LibavfilterLibrary.va_list, com.sun.jna.Pointer, int, com.sun.jna.ptr.IntByReference)} instead
	 */
	@Deprecated 
	void av_log_format_line(Pointer ptr, int level, Pointer fmt, LibavfilterLibrary.va_list vl, Pointer line, int line_size, IntByReference print_prefix);
	/**
	 * Format a line of log the same way as the default callback.<br>
	 * @param line          buffer to receive the formated line<br>
	 * @param line_size     size of the buffer<br>
	 * @param print_prefix  used to store whether the prefix must be printed;<br>
	 *                      must point to a persistent integer initially set to 1<br>
	 * Original signature : <code>void av_log_format_line(void*, int, const char*, va_list, char*, int, int*)</code>
	 */
	void av_log_format_line(Pointer ptr, int level, String fmt, LibavfilterLibrary.va_list vl, ByteBuffer line, int line_size, IntBuffer print_prefix);
	/** Original signature : <code>void av_log_set_flags(int)</code> */
	void av_log_set_flags(int arg);
	/**
	 * Compute the length of an integer list.<br>
	 * * @param elsize  size in bytes of each list element (only 1, 2, 4 or 8)<br>
	 * @param term    list terminator (usually 0 or -1)<br>
	 * @param list    pointer to the list<br>
	 * @return  length of the list, in elements, not counting the terminator<br>
	 * Original signature : <code>int av_int_list_length_for_size(unsigned, const void*, uint64_t)</code>
	 */
	int av_int_list_length_for_size(int elsize, Pointer list, long term);
	/**
	 * Get a dictionary entry with matching key.<br>
	 * * @param prev Set to the previous matching element to find the next.<br>
	 *             If set to NULL the first matching element is returned.<br>
	 * @param flags Allows case as well as suffix-insensitive comparisons.<br>
	 * @return Found entry or NULL, changing key or value leads to undefined behavior.<br>
	 * Original signature : <code>AVDictionaryEntry* av_dict_get(AVDictionary*, const char*, const AVDictionaryEntry*, int)</code><br>
	 * @deprecated use the safer methods {@link #av_dict_get(com.sun.jna.ptr.PointerByReference, java.lang.String, org.javaavc.gen.avfilter.AVDictionaryEntry, int)} and {@link #av_dict_get(com.sun.jna.ptr.PointerByReference, com.sun.jna.Pointer, org.javaavc.gen.avfilter.AVDictionaryEntry, int)} instead
	 */
	@Deprecated 
	AVDictionaryEntry av_dict_get(Pointer m, Pointer key, AVDictionaryEntry prev, int flags);
	/**
	 * Get a dictionary entry with matching key.<br>
	 * * @param prev Set to the previous matching element to find the next.<br>
	 *             If set to NULL the first matching element is returned.<br>
	 * @param flags Allows case as well as suffix-insensitive comparisons.<br>
	 * @return Found entry or NULL, changing key or value leads to undefined behavior.<br>
	 * Original signature : <code>AVDictionaryEntry* av_dict_get(AVDictionary*, const char*, const AVDictionaryEntry*, int)</code>
	 */
	AVDictionaryEntry av_dict_get(PointerByReference m, String key, AVDictionaryEntry prev, int flags);
	/**
	 * Get a dictionary entry with matching key.<br>
	 * * @param prev Set to the previous matching element to find the next.<br>
	 *             If set to NULL the first matching element is returned.<br>
	 * @param flags Allows case as well as suffix-insensitive comparisons.<br>
	 * @return Found entry or NULL, changing key or value leads to undefined behavior.<br>
	 * Original signature : <code>AVDictionaryEntry* av_dict_get(AVDictionary*, const char*, const AVDictionaryEntry*, int)</code>
	 */
	AVDictionaryEntry av_dict_get(PointerByReference m, Pointer key, AVDictionaryEntry prev, int flags);
	/**
	 * Get number of entries in dictionary.<br>
	 * * @param m dictionary<br>
	 * @return  number of entries in dictionary<br>
	 * Original signature : <code>int av_dict_count(const AVDictionary*)</code><br>
	 * @deprecated use the safer method {@link #av_dict_count(com.sun.jna.ptr.PointerByReference)} instead
	 */
	@Deprecated 
	int av_dict_count(Pointer m);
	/**
	 * Get number of entries in dictionary.<br>
	 * * @param m dictionary<br>
	 * @return  number of entries in dictionary<br>
	 * Original signature : <code>int av_dict_count(const AVDictionary*)</code>
	 */
	int av_dict_count(PointerByReference m);
	/**
	 * Set the given entry in *pm, overwriting an existing entry.<br>
	 * * @param pm pointer to a pointer to a dictionary struct. If *pm is NULL<br>
	 * a dictionary struct is allocated and put in *pm.<br>
	 * @param key entry key to add to *pm (will be av_strduped depending on flags)<br>
	 * @param value entry value to add to *pm (will be av_strduped depending on flags).<br>
	 *        Passing a NULL value will cause an existing entry to be deleted.<br>
	 * @return >= 0 on success otherwise an error code <0<br>
	 * Original signature : <code>int av_dict_set(AVDictionary**, const char*, const char*, int)</code><br>
	 * @deprecated use the safer methods {@link #av_dict_set(com.sun.jna.ptr.PointerByReference, java.lang.String, java.lang.String, int)} and {@link #av_dict_set(com.sun.jna.ptr.PointerByReference, com.sun.jna.Pointer, com.sun.jna.Pointer, int)} instead
	 */
	@Deprecated 
	int av_dict_set(PointerByReference pm, Pointer key, Pointer value, int flags);
	/**
	 * Set the given entry in *pm, overwriting an existing entry.<br>
	 * * @param pm pointer to a pointer to a dictionary struct. If *pm is NULL<br>
	 * a dictionary struct is allocated and put in *pm.<br>
	 * @param key entry key to add to *pm (will be av_strduped depending on flags)<br>
	 * @param value entry value to add to *pm (will be av_strduped depending on flags).<br>
	 *        Passing a NULL value will cause an existing entry to be deleted.<br>
	 * @return >= 0 on success otherwise an error code <0<br>
	 * Original signature : <code>int av_dict_set(AVDictionary**, const char*, const char*, int)</code>
	 */
	int av_dict_set(PointerByReference pm, String key, String value, int flags);
	/**
	 * Parse the key/value pairs list and add to a dictionary.<br>
	 * * @param key_val_sep  a 0-terminated list of characters used to separate<br>
	 *                     key from value<br>
	 * @param pairs_sep    a 0-terminated list of characters used to separate<br>
	 *                     two pairs from each other<br>
	 * @param flags        flags to use when adding to dictionary.<br>
	 *                     AV_DICT_DONT_STRDUP_KEY and AV_DICT_DONT_STRDUP_VAL<br>
	 *                     are ignored since the key/value tokens will always<br>
	 *                     be duplicated.<br>
	 * @return             0 on success, negative AVERROR code on failure<br>
	 * Original signature : <code>int av_dict_parse_string(AVDictionary**, const char*, const char*, const char*, int)</code><br>
	 * @deprecated use the safer methods {@link #av_dict_parse_string(com.sun.jna.ptr.PointerByReference, java.lang.String, java.lang.String, java.lang.String, int)} and {@link #av_dict_parse_string(com.sun.jna.ptr.PointerByReference, com.sun.jna.Pointer, com.sun.jna.Pointer, com.sun.jna.Pointer, int)} instead
	 */
	@Deprecated 
	int av_dict_parse_string(PointerByReference pm, Pointer str, Pointer key_val_sep, Pointer pairs_sep, int flags);
	/**
	 * Parse the key/value pairs list and add to a dictionary.<br>
	 * * @param key_val_sep  a 0-terminated list of characters used to separate<br>
	 *                     key from value<br>
	 * @param pairs_sep    a 0-terminated list of characters used to separate<br>
	 *                     two pairs from each other<br>
	 * @param flags        flags to use when adding to dictionary.<br>
	 *                     AV_DICT_DONT_STRDUP_KEY and AV_DICT_DONT_STRDUP_VAL<br>
	 *                     are ignored since the key/value tokens will always<br>
	 *                     be duplicated.<br>
	 * @return             0 on success, negative AVERROR code on failure<br>
	 * Original signature : <code>int av_dict_parse_string(AVDictionary**, const char*, const char*, const char*, int)</code>
	 */
	int av_dict_parse_string(PointerByReference pm, String str, String key_val_sep, String pairs_sep, int flags);
	/**
	 * Copy entries from one AVDictionary struct into another.<br>
	 * @param dst pointer to a pointer to a AVDictionary struct. If *dst is NULL,<br>
	 *            this function will allocate a struct for you and put it in *dst<br>
	 * @param src pointer to source AVDictionary struct<br>
	 * @param flags flags to use when setting entries in *dst<br>
	 * @note metadata is read using the AV_DICT_IGNORE_SUFFIX flag<br>
	 * Original signature : <code>void av_dict_copy(AVDictionary**, AVDictionary*, int)</code><br>
	 * @deprecated use the safer method {@link #av_dict_copy(com.sun.jna.ptr.PointerByReference, com.sun.jna.ptr.PointerByReference, int)} instead
	 */
	@Deprecated 
	void av_dict_copy(PointerByReference dst, Pointer src, int flags);
	/**
	 * Copy entries from one AVDictionary struct into another.<br>
	 * @param dst pointer to a pointer to a AVDictionary struct. If *dst is NULL,<br>
	 *            this function will allocate a struct for you and put it in *dst<br>
	 * @param src pointer to source AVDictionary struct<br>
	 * @param flags flags to use when setting entries in *dst<br>
	 * @note metadata is read using the AV_DICT_IGNORE_SUFFIX flag<br>
	 * Original signature : <code>void av_dict_copy(AVDictionary**, AVDictionary*, int)</code>
	 */
	void av_dict_copy(PointerByReference dst, PointerByReference src, int flags);
	/**
	 * Free all the memory allocated for an AVDictionary struct<br>
	 * and all keys and values.<br>
	 * Original signature : <code>void av_dict_free(AVDictionary**)</code>
	 */
	void av_dict_free(PointerByReference m);
	/**
	 * Allocate an AVBuffer of the given size using av_malloc().<br>
	 * * @return an AVBufferRef of given size or NULL when out of memory<br>
	 * Original signature : <code>AVBufferRef* av_buffer_alloc(int)</code>
	 */
	AVBufferRef av_buffer_alloc(int size);
	/**
	 * Same as av_buffer_alloc(), except the returned buffer will be initialized<br>
	 * to zero.<br>
	 * Original signature : <code>AVBufferRef* av_buffer_allocz(int)</code>
	 */
	AVBufferRef av_buffer_allocz(int size);
	/**
	 * Create an AVBuffer from an existing array.<br>
	 * * If this function is successful, data is owned by the AVBuffer. The caller may<br>
	 * only access data through the returned AVBufferRef and references derived from<br>
	 * it.<br>
	 * If this function fails, data is left untouched.<br>
	 * @param data   data array<br>
	 * @param size   size of data in bytes<br>
	 * @param free   a callback for freeing this buffer's data<br>
	 * @param opaque parameter to be got for processing or passed to free<br>
	 * @param flags  a combination of AV_BUFFER_FLAG_*<br>
	 * * @return an AVBufferRef referring to data on success, NULL on failure.<br>
	 * Original signature : <code>AVBufferRef* av_buffer_create(uint8_t*, int, av_buffer_create_free_callback*, void*, int)</code><br>
	 * @deprecated use the safer methods {@link #av_buffer_create(java.nio.ByteBuffer, int, org.javaavc.gen.avfilter.LibavfilterLibrary.av_buffer_create_free_callback, com.sun.jna.Pointer, int)} and {@link #av_buffer_create(com.sun.jna.Pointer, int, org.javaavc.gen.avfilter.LibavfilterLibrary.av_buffer_create_free_callback, com.sun.jna.Pointer, int)} instead
	 */
	@Deprecated 
	AVBufferRef av_buffer_create(Pointer data, int size, LibavfilterLibrary.av_buffer_create_free_callback free, Pointer opaque, int flags);
	/**
	 * Create an AVBuffer from an existing array.<br>
	 * * If this function is successful, data is owned by the AVBuffer. The caller may<br>
	 * only access data through the returned AVBufferRef and references derived from<br>
	 * it.<br>
	 * If this function fails, data is left untouched.<br>
	 * @param data   data array<br>
	 * @param size   size of data in bytes<br>
	 * @param free   a callback for freeing this buffer's data<br>
	 * @param opaque parameter to be got for processing or passed to free<br>
	 * @param flags  a combination of AV_BUFFER_FLAG_*<br>
	 * * @return an AVBufferRef referring to data on success, NULL on failure.<br>
	 * Original signature : <code>AVBufferRef* av_buffer_create(uint8_t*, int, av_buffer_create_free_callback*, void*, int)</code>
	 */
	AVBufferRef av_buffer_create(ByteBuffer data, int size, LibavfilterLibrary.av_buffer_create_free_callback free, Pointer opaque, int flags);
	/**
	 * Default free callback, which calls av_free() on the buffer data.<br>
	 * This function is meant to be passed to av_buffer_create(), not called<br>
	 * directly.<br>
	 * Original signature : <code>void av_buffer_default_free(void*, uint8_t*)</code><br>
	 * @deprecated use the safer methods {@link #av_buffer_default_free(com.sun.jna.Pointer, java.nio.ByteBuffer)} and {@link #av_buffer_default_free(com.sun.jna.Pointer, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	void av_buffer_default_free(Pointer opaque, Pointer data);
	/**
	 * Default free callback, which calls av_free() on the buffer data.<br>
	 * This function is meant to be passed to av_buffer_create(), not called<br>
	 * directly.<br>
	 * Original signature : <code>void av_buffer_default_free(void*, uint8_t*)</code>
	 */
	void av_buffer_default_free(Pointer opaque, ByteBuffer data);
	/**
	 * Create a new reference to an AVBuffer.<br>
	 * * @return a new AVBufferRef referring to the same AVBuffer as buf or NULL on<br>
	 * failure.<br>
	 * Original signature : <code>AVBufferRef* av_buffer_ref(AVBufferRef*)</code>
	 */
	AVBufferRef av_buffer_ref(AVBufferRef buf);
	/**
	 * Free a given reference and automatically free the buffer if there are no more<br>
	 * references to it.<br>
	 * * @param buf the reference to be freed. The pointer is set to NULL on return.<br>
	 * Original signature : <code>void av_buffer_unref(AVBufferRef**)</code><br>
	 * @deprecated use the safer method {@link #av_buffer_unref(org.javaavc.gen.avfilter.AVBufferRef.ByReference[])} instead
	 */
	@Deprecated 
	void av_buffer_unref(PointerByReference buf);
	/**
	 * Free a given reference and automatically free the buffer if there are no more<br>
	 * references to it.<br>
	 * * @param buf the reference to be freed. The pointer is set to NULL on return.<br>
	 * Original signature : <code>void av_buffer_unref(AVBufferRef**)</code>
	 */
	void av_buffer_unref(AVBufferRef.ByReference buf[]);
	/**
	 * @return 1 if the caller may write to the data referred to by buf (which is<br>
	 * true if and only if buf is the only reference to the underlying AVBuffer).<br>
	 * Return 0 otherwise.<br>
	 * A positive answer is valid until av_buffer_ref() is called on buf.<br>
	 * Original signature : <code>int av_buffer_is_writable(const AVBufferRef*)</code>
	 */
	int av_buffer_is_writable(AVBufferRef buf);
	/**
	 * @return the opaque parameter set by av_buffer_create.<br>
	 * Original signature : <code>void* av_buffer_get_opaque(const AVBufferRef*)</code>
	 */
	Pointer av_buffer_get_opaque(AVBufferRef buf);
	/** Original signature : <code>int av_buffer_get_ref_count(const AVBufferRef*)</code> */
	int av_buffer_get_ref_count(AVBufferRef buf);
	/**
	 * Create a writable reference from a given buffer reference, avoiding data copy<br>
	 * if possible.<br>
	 * * @param buf buffer reference to make writable. On success, buf is either left<br>
	 *            untouched, or it is unreferenced and a new writable AVBufferRef is<br>
	 *            written in its place. On failure, buf is left untouched.<br>
	 * @return 0 on success, a negative AVERROR on failure.<br>
	 * Original signature : <code>int av_buffer_make_writable(AVBufferRef**)</code><br>
	 * @deprecated use the safer method {@link #av_buffer_make_writable(org.javaavc.gen.avfilter.AVBufferRef.ByReference[])} instead
	 */
	@Deprecated 
	int av_buffer_make_writable(PointerByReference buf);
	/**
	 * Create a writable reference from a given buffer reference, avoiding data copy<br>
	 * if possible.<br>
	 * * @param buf buffer reference to make writable. On success, buf is either left<br>
	 *            untouched, or it is unreferenced and a new writable AVBufferRef is<br>
	 *            written in its place. On failure, buf is left untouched.<br>
	 * @return 0 on success, a negative AVERROR on failure.<br>
	 * Original signature : <code>int av_buffer_make_writable(AVBufferRef**)</code>
	 */
	int av_buffer_make_writable(AVBufferRef.ByReference buf[]);
	/**
	 * Reallocate a given buffer.<br>
	 * * @param buf  a buffer reference to reallocate. On success, buf will be<br>
	 *             unreferenced and a new reference with the required size will be<br>
	 *             written in its place. On failure buf will be left untouched. *buf<br>
	 *             may be NULL, then a new buffer is allocated.<br>
	 * @param size required new buffer size.<br>
	 * @return 0 on success, a negative AVERROR on failure.<br>
	 * * @note the buffer is actually reallocated with av_realloc() only if it was<br>
	 * initially allocated through av_buffer_realloc(NULL) and there is only one<br>
	 * reference to it (i.e. the one passed to this function). In all other cases<br>
	 * a new buffer is allocated and the data is copied.<br>
	 * Original signature : <code>int av_buffer_realloc(AVBufferRef**, int)</code><br>
	 * @deprecated use the safer method {@link #av_buffer_realloc(org.javaavc.gen.avfilter.AVBufferRef.ByReference[], int)} instead
	 */
	@Deprecated 
	int av_buffer_realloc(PointerByReference buf, int size);
	/**
	 * Reallocate a given buffer.<br>
	 * * @param buf  a buffer reference to reallocate. On success, buf will be<br>
	 *             unreferenced and a new reference with the required size will be<br>
	 *             written in its place. On failure buf will be left untouched. *buf<br>
	 *             may be NULL, then a new buffer is allocated.<br>
	 * @param size required new buffer size.<br>
	 * @return 0 on success, a negative AVERROR on failure.<br>
	 * * @note the buffer is actually reallocated with av_realloc() only if it was<br>
	 * initially allocated through av_buffer_realloc(NULL) and there is only one<br>
	 * reference to it (i.e. the one passed to this function). In all other cases<br>
	 * a new buffer is allocated and the data is copied.<br>
	 * Original signature : <code>int av_buffer_realloc(AVBufferRef**, int)</code>
	 */
	int av_buffer_realloc(AVBufferRef.ByReference buf[], int size);
	/**
	 * Allocate and initialize a buffer pool.<br>
	 * * @param size size of each buffer in this pool<br>
	 * @param alloc a function that will be used to allocate new buffers when the<br>
	 * pool is empty. May be NULL, then the default allocator will be used<br>
	 * (av_buffer_alloc()).<br>
	 * @return newly created buffer pool on success, NULL on error.<br>
	 * Original signature : <code>AVBufferPool* av_buffer_pool_init(int, av_buffer_pool_init_alloc_callback*)</code>
	 */
	PointerByReference av_buffer_pool_init(int size, LibavfilterLibrary.av_buffer_pool_init_alloc_callback alloc);
	/**
	 * Mark the pool as being available for freeing. It will actually be freed only<br>
	 * once all the allocated buffers associated with the pool are released. Thus it<br>
	 * is safe to call this function while some of the allocated buffers are still<br>
	 * in use.<br>
	 * * @param pool pointer to the pool to be freed. It will be set to NULL.<br>
	 * @see av_buffer_pool_can_uninit()<br>
	 * Original signature : <code>void av_buffer_pool_uninit(AVBufferPool**)</code>
	 */
	void av_buffer_pool_uninit(PointerByReference pool);
	/**
	 * Allocate a new AVBuffer, reusing an old buffer from the pool when available.<br>
	 * This function may be called simultaneously from multiple threads.<br>
	 * * @return a reference to the new buffer on success, NULL on error.<br>
	 * Original signature : <code>AVBufferRef* av_buffer_pool_get(AVBufferPool*)</code><br>
	 * @deprecated use the safer method {@link #av_buffer_pool_get(com.sun.jna.ptr.PointerByReference)} instead
	 */
	@Deprecated 
	AVBufferRef av_buffer_pool_get(Pointer pool);
	/**
	 * Allocate a new AVBuffer, reusing an old buffer from the pool when available.<br>
	 * This function may be called simultaneously from multiple threads.<br>
	 * * @return a reference to the new buffer on success, NULL on error.<br>
	 * Original signature : <code>AVBufferRef* av_buffer_pool_get(AVBufferPool*)</code>
	 */
	AVBufferRef av_buffer_pool_get(PointerByReference pool);
	/**
	 * Return the name of sample_fmt, or NULL if sample_fmt is not<br>
	 * recognized.<br>
	 * Original signature : <code>char* av_get_sample_fmt_name(AVSampleFormat)</code>
	 */
	String av_get_sample_fmt_name(int sample_fmt);
	/**
	 * Return a sample format corresponding to name, or AV_SAMPLE_FMT_NONE<br>
	 * on error.<br>
	 * Original signature : <code>AVSampleFormat av_get_sample_fmt(const char*)</code><br>
	 * @deprecated use the safer methods {@link #av_get_sample_fmt(java.lang.String)} and {@link #av_get_sample_fmt(com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	int av_get_sample_fmt(Pointer name);
	/**
	 * Return a sample format corresponding to name, or AV_SAMPLE_FMT_NONE<br>
	 * on error.<br>
	 * Original signature : <code>AVSampleFormat av_get_sample_fmt(const char*)</code>
	 */
	int av_get_sample_fmt(String name);
	/**
	 * Return the planar<->packed alternative form of the given sample format, or<br>
	 * AV_SAMPLE_FMT_NONE on error. If the passed sample_fmt is already in the<br>
	 * requested planar/packed format, the format returned is the same as the<br>
	 * input.<br>
	 * Original signature : <code>AVSampleFormat av_get_alt_sample_fmt(AVSampleFormat, int)</code>
	 */
	int av_get_alt_sample_fmt(int sample_fmt, int planar);
	/**
	 * Get the packed alternative form of the given sample format.<br>
	 * * If the passed sample_fmt is already in packed format, the format returned is<br>
	 * the same as the input.<br>
	 * * @return  the packed alternative form of the given sample format or<br>
	 * AV_SAMPLE_FMT_NONE on error.<br>
	 * Original signature : <code>AVSampleFormat av_get_packed_sample_fmt(AVSampleFormat)</code>
	 */
	int av_get_packed_sample_fmt(int sample_fmt);
	/**
	 * Get the planar alternative form of the given sample format.<br>
	 * * If the passed sample_fmt is already in planar format, the format returned is<br>
	 * the same as the input.<br>
	 * * @return  the planar alternative form of the given sample format or<br>
	 * AV_SAMPLE_FMT_NONE on error.<br>
	 * Original signature : <code>AVSampleFormat av_get_planar_sample_fmt(AVSampleFormat)</code>
	 */
	int av_get_planar_sample_fmt(int sample_fmt);
	/**
	 * Generate a string corresponding to the sample format with<br>
	 * sample_fmt, or a header if sample_fmt is negative.<br>
	 * * @param buf the buffer where to write the string<br>
	 * @param buf_size the size of buf<br>
	 * @param sample_fmt the number of the sample format to print the<br>
	 * corresponding info string, or a negative value to print the<br>
	 * corresponding header.<br>
	 * @return the pointer to the filled buffer or NULL if sample_fmt is<br>
	 * unknown or in case of other errors<br>
	 * Original signature : <code>char* av_get_sample_fmt_string(char*, int, AVSampleFormat)</code><br>
	 * @deprecated use the safer methods {@link #av_get_sample_fmt_string(java.nio.ByteBuffer, int, int)} and {@link #av_get_sample_fmt_string(com.sun.jna.Pointer, int, int)} instead
	 */
	@Deprecated 
	Pointer av_get_sample_fmt_string(Pointer buf, int buf_size, int sample_fmt);
	/**
	 * Generate a string corresponding to the sample format with<br>
	 * sample_fmt, or a header if sample_fmt is negative.<br>
	 * * @param buf the buffer where to write the string<br>
	 * @param buf_size the size of buf<br>
	 * @param sample_fmt the number of the sample format to print the<br>
	 * corresponding info string, or a negative value to print the<br>
	 * corresponding header.<br>
	 * @return the pointer to the filled buffer or NULL if sample_fmt is<br>
	 * unknown or in case of other errors<br>
	 * Original signature : <code>char* av_get_sample_fmt_string(char*, int, AVSampleFormat)</code>
	 */
	Pointer av_get_sample_fmt_string(ByteBuffer buf, int buf_size, int sample_fmt);
	/** Original signature : <code>int av_get_bits_per_sample_fmt(AVSampleFormat)</code> */
	int av_get_bits_per_sample_fmt(int sample_fmt);
	/**
	 * Return number of bytes per sample.<br>
	 * * @param sample_fmt the sample format<br>
	 * @return number of bytes per sample or zero if unknown for the given<br>
	 * sample format<br>
	 * Original signature : <code>int av_get_bytes_per_sample(AVSampleFormat)</code>
	 */
	int av_get_bytes_per_sample(int sample_fmt);
	/**
	 * Check if the sample format is planar.<br>
	 * * @param sample_fmt the sample format to inspect<br>
	 * @return 1 if the sample format is planar, 0 if it is interleaved<br>
	 * Original signature : <code>int av_sample_fmt_is_planar(AVSampleFormat)</code>
	 */
	int av_sample_fmt_is_planar(int sample_fmt);
	/**
	 * Get the required buffer size for the given audio parameters.<br>
	 * * @param[out] linesize calculated linesize, may be NULL<br>
	 * @param nb_channels   the number of channels<br>
	 * @param nb_samples    the number of samples in a single channel<br>
	 * @param sample_fmt    the sample format<br>
	 * @param align         buffer size alignment (0 = default, 1 = no alignment)<br>
	 * @return              required buffer size, or negative error code on failure<br>
	 * Original signature : <code>int av_samples_get_buffer_size(int*, int, int, AVSampleFormat, int)</code><br>
	 * @deprecated use the safer methods {@link #av_samples_get_buffer_size(java.nio.IntBuffer, int, int, int, int)} and {@link #av_samples_get_buffer_size(com.sun.jna.ptr.IntByReference, int, int, int, int)} instead
	 */
	@Deprecated 
	int av_samples_get_buffer_size(IntByReference linesize, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Get the required buffer size for the given audio parameters.<br>
	 * * @param[out] linesize calculated linesize, may be NULL<br>
	 * @param nb_channels   the number of channels<br>
	 * @param nb_samples    the number of samples in a single channel<br>
	 * @param sample_fmt    the sample format<br>
	 * @param align         buffer size alignment (0 = default, 1 = no alignment)<br>
	 * @return              required buffer size, or negative error code on failure<br>
	 * Original signature : <code>int av_samples_get_buffer_size(int*, int, int, AVSampleFormat, int)</code>
	 */
	int av_samples_get_buffer_size(IntBuffer linesize, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Fill plane data pointers and linesize for samples with sample<br>
	 * format sample_fmt.<br>
	 * * The audio_data array is filled with the pointers to the samples data planes:<br>
	 * for planar, set the start point of each channel's data within the buffer,<br>
	 * for packed, set the start point of the entire buffer only.<br>
	 * * The value pointed to by linesize is set to the aligned size of each<br>
	 * channel's data buffer for planar layout, or to the aligned size of the<br>
	 * buffer for all channels for packed layout.<br>
	 * * The buffer in buf must be big enough to contain all the samples<br>
	 * (use av_samples_get_buffer_size() to compute its minimum size),<br>
	 * otherwise the audio_data pointers will point to invalid data.<br>
	 * * @see enum AVSampleFormat<br>
	 * The documentation for AVSampleFormat describes the data layout.<br>
	 * * @param[out] audio_data  array to be filled with the pointer for each channel<br>
	 * @param[out] linesize    calculated linesize, may be NULL<br>
	 * @param buf              the pointer to a buffer containing the samples<br>
	 * @param nb_channels      the number of channels<br>
	 * @param nb_samples       the number of samples in a single channel<br>
	 * @param sample_fmt       the sample format<br>
	 * @param align            buffer size alignment (0 = default, 1 = no alignment)<br>
	 * @return                 >=0 on success or a negative error code on failure<br>
	 * @todo return minimum size in bytes required for the buffer in case<br>
	 * of success at the next bump<br>
	 * Original signature : <code>int av_samples_fill_arrays(uint8_t**, int*, const uint8_t*, int, int, AVSampleFormat, int)</code><br>
	 * @deprecated use the safer methods {@link #av_samples_fill_arrays(com.sun.jna.ptr.PointerByReference, java.nio.IntBuffer, java.nio.ByteBuffer, int, int, int, int)} and {@link #av_samples_fill_arrays(com.sun.jna.ptr.PointerByReference, com.sun.jna.ptr.IntByReference, com.sun.jna.Pointer, int, int, int, int)} instead
	 */
	@Deprecated 
	int av_samples_fill_arrays(PointerByReference audio_data, IntByReference linesize, Pointer buf, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Fill plane data pointers and linesize for samples with sample<br>
	 * format sample_fmt.<br>
	 * * The audio_data array is filled with the pointers to the samples data planes:<br>
	 * for planar, set the start point of each channel's data within the buffer,<br>
	 * for packed, set the start point of the entire buffer only.<br>
	 * * The value pointed to by linesize is set to the aligned size of each<br>
	 * channel's data buffer for planar layout, or to the aligned size of the<br>
	 * buffer for all channels for packed layout.<br>
	 * * The buffer in buf must be big enough to contain all the samples<br>
	 * (use av_samples_get_buffer_size() to compute its minimum size),<br>
	 * otherwise the audio_data pointers will point to invalid data.<br>
	 * * @see enum AVSampleFormat<br>
	 * The documentation for AVSampleFormat describes the data layout.<br>
	 * * @param[out] audio_data  array to be filled with the pointer for each channel<br>
	 * @param[out] linesize    calculated linesize, may be NULL<br>
	 * @param buf              the pointer to a buffer containing the samples<br>
	 * @param nb_channels      the number of channels<br>
	 * @param nb_samples       the number of samples in a single channel<br>
	 * @param sample_fmt       the sample format<br>
	 * @param align            buffer size alignment (0 = default, 1 = no alignment)<br>
	 * @return                 >=0 on success or a negative error code on failure<br>
	 * @todo return minimum size in bytes required for the buffer in case<br>
	 * of success at the next bump<br>
	 * Original signature : <code>int av_samples_fill_arrays(uint8_t**, int*, const uint8_t*, int, int, AVSampleFormat, int)</code>
	 */
	int av_samples_fill_arrays(PointerByReference audio_data, IntBuffer linesize, ByteBuffer buf, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Allocate a samples buffer for nb_samples samples, and fill data pointers and<br>
	 * linesize accordingly.<br>
	 * The allocated samples buffer can be freed by using av_freep(&audio_data[0])<br>
	 * Allocated data will be initialized to silence.<br>
	 * * @see enum AVSampleFormat<br>
	 * The documentation for AVSampleFormat describes the data layout.<br>
	 * * @param[out] audio_data  array to be filled with the pointer for each channel<br>
	 * @param[out] linesize    aligned size for audio buffer(s), may be NULL<br>
	 * @param nb_channels      number of audio channels<br>
	 * @param nb_samples       number of samples per channel<br>
	 * @param align            buffer size alignment (0 = default, 1 = no alignment)<br>
	 * @return                 >=0 on success or a negative error code on failure<br>
	 * @todo return the size of the allocated buffer in case of success at the next bump<br>
	 * @see av_samples_fill_arrays()<br>
	 * @see av_samples_alloc_array_and_samples()<br>
	 * Original signature : <code>int av_samples_alloc(uint8_t**, int*, int, int, AVSampleFormat, int)</code><br>
	 * @deprecated use the safer methods {@link #av_samples_alloc(com.sun.jna.ptr.PointerByReference, java.nio.IntBuffer, int, int, int, int)} and {@link #av_samples_alloc(com.sun.jna.ptr.PointerByReference, com.sun.jna.ptr.IntByReference, int, int, int, int)} instead
	 */
	@Deprecated 
	int av_samples_alloc(PointerByReference audio_data, IntByReference linesize, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Allocate a samples buffer for nb_samples samples, and fill data pointers and<br>
	 * linesize accordingly.<br>
	 * The allocated samples buffer can be freed by using av_freep(&audio_data[0])<br>
	 * Allocated data will be initialized to silence.<br>
	 * * @see enum AVSampleFormat<br>
	 * The documentation for AVSampleFormat describes the data layout.<br>
	 * * @param[out] audio_data  array to be filled with the pointer for each channel<br>
	 * @param[out] linesize    aligned size for audio buffer(s), may be NULL<br>
	 * @param nb_channels      number of audio channels<br>
	 * @param nb_samples       number of samples per channel<br>
	 * @param align            buffer size alignment (0 = default, 1 = no alignment)<br>
	 * @return                 >=0 on success or a negative error code on failure<br>
	 * @todo return the size of the allocated buffer in case of success at the next bump<br>
	 * @see av_samples_fill_arrays()<br>
	 * @see av_samples_alloc_array_and_samples()<br>
	 * Original signature : <code>int av_samples_alloc(uint8_t**, int*, int, int, AVSampleFormat, int)</code>
	 */
	int av_samples_alloc(PointerByReference audio_data, IntBuffer linesize, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Allocate a data pointers array, samples buffer for nb_samples<br>
	 * samples, and fill data pointers and linesize accordingly.<br>
	 * * This is the same as av_samples_alloc(), but also allocates the data<br>
	 * pointers array.<br>
	 * * @see av_samples_alloc()<br>
	 * Original signature : <code>int av_samples_alloc_array_and_samples(uint8_t***, int*, int, int, AVSampleFormat, int)</code><br>
	 * @deprecated use the safer methods {@link #av_samples_alloc_array_and_samples(com.sun.jna.ptr.PointerByReference, java.nio.IntBuffer, int, int, int, int)} and {@link #av_samples_alloc_array_and_samples(com.sun.jna.ptr.PointerByReference, com.sun.jna.ptr.IntByReference, int, int, int, int)} instead
	 */
	@Deprecated 
	int av_samples_alloc_array_and_samples(PointerByReference audio_data, IntByReference linesize, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Allocate a data pointers array, samples buffer for nb_samples<br>
	 * samples, and fill data pointers and linesize accordingly.<br>
	 * * This is the same as av_samples_alloc(), but also allocates the data<br>
	 * pointers array.<br>
	 * * @see av_samples_alloc()<br>
	 * Original signature : <code>int av_samples_alloc_array_and_samples(uint8_t***, int*, int, int, AVSampleFormat, int)</code>
	 */
	int av_samples_alloc_array_and_samples(PointerByReference audio_data, IntBuffer linesize, int nb_channels, int nb_samples, int sample_fmt, int align);
	/**
	 * Copy samples from src to dst.<br>
	 * * @param dst destination array of pointers to data planes<br>
	 * @param src source array of pointers to data planes<br>
	 * @param dst_offset offset in samples at which the data will be written to dst<br>
	 * @param src_offset offset in samples at which the data will be read from src<br>
	 * @param nb_samples number of samples to be copied<br>
	 * @param nb_channels number of audio channels<br>
	 * @param sample_fmt audio sample format<br>
	 * Original signature : <code>int av_samples_copy(uint8_t**, const uint8_t**, int, int, int, int, AVSampleFormat)</code>
	 */
	int av_samples_copy(PointerByReference dst, PointerByReference src, int dst_offset, int src_offset, int nb_samples, int nb_channels, int sample_fmt);
	/**
	 * Fill an audio buffer with silence.<br>
	 * * @param audio_data  array of pointers to data planes<br>
	 * @param offset      offset in samples at which to start filling<br>
	 * @param nb_samples  number of samples to fill<br>
	 * @param nb_channels number of audio channels<br>
	 * @param sample_fmt  audio sample format<br>
	 * Original signature : <code>int av_samples_set_silence(uint8_t**, int, int, int, AVSampleFormat)</code>
	 */
	int av_samples_set_silence(PointerByReference audio_data, int offset, int nb_samples, int nb_channels, int sample_fmt);
	/**
	 * Accessors for some AVFrame fields.<br>
	 * The position of these field in the structure is not part of the ABI,<br>
	 * they should not be accessed directly outside libavcodec.<br>
	 * Original signature : <code>int64_t av_frame_get_best_effort_timestamp(const AVFrame*)</code>
	 */
	long av_frame_get_best_effort_timestamp(AVFrame frame);
	/** Original signature : <code>void av_frame_set_best_effort_timestamp(AVFrame*, int64_t)</code> */
	void av_frame_set_best_effort_timestamp(AVFrame frame, long val);
	/** Original signature : <code>int64_t av_frame_get_pkt_duration(const AVFrame*)</code> */
	long av_frame_get_pkt_duration(AVFrame frame);
	/** Original signature : <code>void av_frame_set_pkt_duration(AVFrame*, int64_t)</code> */
	void av_frame_set_pkt_duration(AVFrame frame, long val);
	/** Original signature : <code>int64_t av_frame_get_pkt_pos(const AVFrame*)</code> */
	long av_frame_get_pkt_pos(AVFrame frame);
	/** Original signature : <code>void av_frame_set_pkt_pos(AVFrame*, int64_t)</code> */
	void av_frame_set_pkt_pos(AVFrame frame, long val);
	/** Original signature : <code>int64_t av_frame_get_channel_layout(const AVFrame*)</code> */
	long av_frame_get_channel_layout(AVFrame frame);
	/** Original signature : <code>void av_frame_set_channel_layout(AVFrame*, int64_t)</code> */
	void av_frame_set_channel_layout(AVFrame frame, long val);
	/** Original signature : <code>int av_frame_get_channels(const AVFrame*)</code> */
	int av_frame_get_channels(AVFrame frame);
	/** Original signature : <code>void av_frame_set_channels(AVFrame*, int)</code> */
	void av_frame_set_channels(AVFrame frame, int val);
	/** Original signature : <code>int av_frame_get_sample_rate(const AVFrame*)</code> */
	int av_frame_get_sample_rate(AVFrame frame);
	/** Original signature : <code>void av_frame_set_sample_rate(AVFrame*, int)</code> */
	void av_frame_set_sample_rate(AVFrame frame, int val);
	/** Original signature : <code>AVDictionary* av_frame_get_metadata(const AVFrame*)</code> */
	PointerByReference av_frame_get_metadata(AVFrame frame);
	/**
	 * Original signature : <code>void av_frame_set_metadata(AVFrame*, AVDictionary*)</code><br>
	 * @deprecated use the safer method {@link #av_frame_set_metadata(org.javaavc.gen.avfilter.AVFrame, com.sun.jna.ptr.PointerByReference)} instead
	 */
	@Deprecated 
	void av_frame_set_metadata(AVFrame frame, Pointer val);
	/** Original signature : <code>void av_frame_set_metadata(AVFrame*, AVDictionary*)</code> */
	void av_frame_set_metadata(AVFrame frame, PointerByReference val);
	/** Original signature : <code>int av_frame_get_decode_error_flags(const AVFrame*)</code> */
	int av_frame_get_decode_error_flags(AVFrame frame);
	/** Original signature : <code>void av_frame_set_decode_error_flags(AVFrame*, int)</code> */
	void av_frame_set_decode_error_flags(AVFrame frame, int val);
	/** Original signature : <code>int av_frame_get_pkt_size(const AVFrame*)</code> */
	int av_frame_get_pkt_size(AVFrame frame);
	/** Original signature : <code>void av_frame_set_pkt_size(AVFrame*, int)</code> */
	void av_frame_set_pkt_size(AVFrame frame, int val);
	/** Original signature : <code>AVDictionary** avpriv_frame_get_metadatap(AVFrame*)</code> */
	PointerByReference avpriv_frame_get_metadatap(AVFrame frame);
	/**
	 * Original signature : <code>int8_t* av_frame_get_qp_table(AVFrame*, int*, int*)</code><br>
	 * @deprecated use the safer methods {@link #av_frame_get_qp_table(org.javaavc.gen.avfilter.AVFrame, java.nio.IntBuffer, java.nio.IntBuffer)} and {@link #av_frame_get_qp_table(org.javaavc.gen.avfilter.AVFrame, com.sun.jna.ptr.IntByReference, com.sun.jna.ptr.IntByReference)} instead
	 */
	@Deprecated 
	Pointer av_frame_get_qp_table(AVFrame f, IntByReference stride, IntByReference type);
	/** Original signature : <code>int8_t* av_frame_get_qp_table(AVFrame*, int*, int*)</code> */
	Pointer av_frame_get_qp_table(AVFrame f, IntBuffer stride, IntBuffer type);
	/** Original signature : <code>int av_frame_set_qp_table(AVFrame*, AVBufferRef*, int, int)</code> */
	int av_frame_set_qp_table(AVFrame f, AVBufferRef buf, int stride, int type);
	/**
	 * Allocate an AVFrame and set its fields to default values.  The resulting<br>
	 * struct must be freed using av_frame_free().<br>
	 * * @return An AVFrame filled with default values or NULL on failure.<br>
	 * * @note this only allocates the AVFrame itself, not the data buffers. Those<br>
	 * must be allocated through other means, e.g. with av_frame_get_buffer() or<br>
	 * manually.<br>
	 * Original signature : <code>AVFrame* av_frame_alloc()</code>
	 */
	AVFrame av_frame_alloc();
	/**
	 * Free the frame and any dynamically allocated objects in it,<br>
	 * e.g. extended_data. If the frame is reference counted, it will be<br>
	 * unreferenced first.<br>
	 * * @param frame frame to be freed. The pointer will be set to NULL.<br>
	 * Original signature : <code>void av_frame_free(AVFrame**)</code><br>
	 * @deprecated use the safer method {@link #av_frame_free(org.javaavc.gen.avfilter.AVFrame.ByReference[])} instead
	 */
	@Deprecated 
	void av_frame_free(PointerByReference frame);
	/**
	 * Free the frame and any dynamically allocated objects in it,<br>
	 * e.g. extended_data. If the frame is reference counted, it will be<br>
	 * unreferenced first.<br>
	 * * @param frame frame to be freed. The pointer will be set to NULL.<br>
	 * Original signature : <code>void av_frame_free(AVFrame**)</code>
	 */
	void av_frame_free(AVFrame.ByReference frame[]);
	/**
	 * Setup a new reference to the data described by an given frame.<br>
	 * * Copy frame properties from src to dst and create a new reference for each<br>
	 * AVBufferRef from src.<br>
	 * * If src is not reference counted, new buffers are allocated and the data is<br>
	 * copied.<br>
	 * * @return 0 on success, a negative AVERROR on error<br>
	 * Original signature : <code>int av_frame_ref(AVFrame*, AVFrame*)</code>
	 */
	int av_frame_ref(AVFrame dst, AVFrame src);
	/**
	 * Create a new frame that references the same data as src.<br>
	 * * This is a shortcut for av_frame_alloc()+av_frame_ref().<br>
	 * * @return newly created AVFrame on success, NULL on error.<br>
	 * Original signature : <code>AVFrame* av_frame_clone(AVFrame*)</code>
	 */
	AVFrame av_frame_clone(AVFrame src);
	/**
	 * Unreference all the buffers referenced by frame and reset the frame fields.<br>
	 * Original signature : <code>void av_frame_unref(AVFrame*)</code>
	 */
	void av_frame_unref(AVFrame frame);
	/**
	 * Move everythnig contained in src to dst and reset src.<br>
	 * Original signature : <code>void av_frame_move_ref(AVFrame*, AVFrame*)</code>
	 */
	void av_frame_move_ref(AVFrame dst, AVFrame src);
	/**
	 * Allocate new buffer(s) for audio or video data.<br>
	 * * The following fields must be set on frame before calling this function:<br>
	 * - format (pixel format for video, sample format for audio)<br>
	 * - width and height for video<br>
	 * - nb_samples and channel_layout for audio<br>
	 * * This function will fill AVFrame.data and AVFrame.buf arrays and, if<br>
	 * necessary, allocate and fill AVFrame.extended_data and AVFrame.extended_buf.<br>
	 * For planar formats, one buffer will be allocated for each plane.<br>
	 * * @param frame frame in which to store the new buffers.<br>
	 * @param align required buffer size alignment<br>
	 * * @return 0 on success, a negative AVERROR on error.<br>
	 * Original signature : <code>int av_frame_get_buffer(AVFrame*, int)</code>
	 */
	int av_frame_get_buffer(AVFrame frame, int align);
	/**
	 * Check if the frame data is writable.<br>
	 * * @return A positive value if the frame data is writable (which is true if and<br>
	 * only if each of the underlying buffers has only one reference, namely the one<br>
	 * stored in this frame). Return 0 otherwise.<br>
	 * * If 1 is returned the answer is valid until av_buffer_ref() is called on any<br>
	 * of the underlying AVBufferRefs (e.g. through av_frame_ref() or directly).<br>
	 * * @see av_frame_make_writable(), av_buffer_is_writable()<br>
	 * Original signature : <code>int av_frame_is_writable(AVFrame*)</code>
	 */
	int av_frame_is_writable(AVFrame frame);
	/**
	 * Ensure that the frame data is writable, avoiding data copy if possible.<br>
	 * * Do nothing if the frame is writable, allocate new buffers and copy the data<br>
	 * if it is not.<br>
	 * * @return 0 on success, a negative AVERROR on error.<br>
	 * * @see av_frame_is_writable(), av_buffer_is_writable(),<br>
	 * av_buffer_make_writable()<br>
	 * Original signature : <code>int av_frame_make_writable(AVFrame*)</code>
	 */
	int av_frame_make_writable(AVFrame frame);
	/**
	 * Copy only "metadata" fields from src to dst.<br>
	 * * Metadata for the purpose of this function are those fields that do not affect<br>
	 * the data layout in the buffers.  E.g. pts, sample rate (for audio) or sample<br>
	 * aspect ratio (for video), but not width/height or channel layout.<br>
	 * Side data is also copied.<br>
	 * Original signature : <code>int av_frame_copy_props(AVFrame*, const AVFrame*)</code>
	 */
	int av_frame_copy_props(AVFrame dst, AVFrame src);
	/**
	 * Get the buffer reference a given data plane is stored in.<br>
	 * * @param plane index of the data plane of interest in frame->extended_data.<br>
	 * * @return the buffer reference that contains the plane or NULL if the input<br>
	 * frame is not valid.<br>
	 * Original signature : <code>AVBufferRef* av_frame_get_plane_buffer(AVFrame*, int)</code>
	 */
	AVBufferRef av_frame_get_plane_buffer(AVFrame frame, int plane);
	/**
	 * Add a new side data to a frame.<br>
	 * * @param frame a frame to which the side data should be added<br>
	 * @param type type of the added side data<br>
	 * @param size size of the side data<br>
	 * * @return newly added side data on success, NULL on error<br>
	 * Original signature : <code>AVFrameSideData* av_frame_new_side_data(AVFrame*, AVFrameSideDataType, int)</code>
	 */
	AVFrameSideData av_frame_new_side_data(AVFrame frame, int type, int size);
	/**
	 * @return a pointer to the side data of a given type on success, NULL if there<br>
	 * is no side data with such type in this frame.<br>
	 * Original signature : <code>AVFrameSideData* av_frame_get_side_data(AVFrame*, AVFrameSideDataType)</code>
	 */
	AVFrameSideData av_frame_get_side_data(AVFrame frame, int type);
	/**
	 * Return the LIBAVFILTER_VERSION_INT constant.<br>
	 * Original signature : <code>int avfilter_version()</code>
	 */
	int avfilter_version();
	/**
	 * Return the libavfilter build-time configuration.<br>
	 * Original signature : <code>char* avfilter_configuration()</code>
	 */
	String avfilter_configuration();
	/**
	 * Return the libavfilter license.<br>
	 * Original signature : <code>char* avfilter_license()</code>
	 */
	String avfilter_license();
	/** Original signature : <code>void avfilter_copy_buffer_ref_props(AVFilterBufferRef*, AVFilterBufferRef*)</code> */
	void avfilter_copy_buffer_ref_props(AVFilterBufferRef dst, AVFilterBufferRef src);
	/** Original signature : <code>AVFilterBufferRef* avfilter_ref_buffer(AVFilterBufferRef*, int)</code> */
	AVFilterBufferRef avfilter_ref_buffer(AVFilterBufferRef ref, int pmask);
	/** Original signature : <code>void avfilter_unref_buffer(AVFilterBufferRef*)</code> */
	void avfilter_unref_buffer(AVFilterBufferRef ref);
	/**
	 * Original signature : <code>void avfilter_unref_bufferp(AVFilterBufferRef**)</code><br>
	 * @deprecated use the safer method {@link #avfilter_unref_bufferp(org.javaavc.gen.avfilter.AVFilterBufferRef.ByReference[])} instead
	 */
	@Deprecated 
	void avfilter_unref_bufferp(PointerByReference ref);
	/** Original signature : <code>void avfilter_unref_bufferp(AVFilterBufferRef**)</code> */
	void avfilter_unref_bufferp(AVFilterBufferRef.ByReference ref[]);
	/** Original signature : <code>int avfilter_ref_get_channels(AVFilterBufferRef*)</code> */
	int avfilter_ref_get_channels(AVFilterBufferRef ref);
	/**
	 * Get the number of elements in a NULL-terminated array of AVFilterPads (e.g.<br>
	 * AVFilter.inputs/outputs).<br>
	 * Original signature : <code>int avfilter_pad_count(const AVFilterPad*)</code>
	 */
	int avfilter_pad_count(AVFilterPad pads);
	/**
	 * Get the name of an AVFilterPad.<br>
	 * * @param pads an array of AVFilterPads<br>
	 * @param pad_idx index of the pad in the array it; is the caller's<br>
	 *                responsibility to ensure the index is valid<br>
	 * * @return name of the pad_idx'th pad in pads<br>
	 * Original signature : <code>char* avfilter_pad_get_name(const AVFilterPad*, int)</code>
	 */
	String avfilter_pad_get_name(AVFilterPad pads, int pad_idx);
	/**
	 * Get the type of an AVFilterPad.<br>
	 * * @param pads an array of AVFilterPads<br>
	 * @param pad_idx index of the pad in the array; it is the caller's<br>
	 *                responsibility to ensure the index is valid<br>
	 * * @return type of the pad_idx'th pad in pads<br>
	 * Original signature : <code>AVMediaType avfilter_pad_get_type(const AVFilterPad*, int)</code>
	 */
	int avfilter_pad_get_type(AVFilterPad pads, int pad_idx);
	/**
	 * Link two filters together.<br>
	 * * @param src    the source filter<br>
	 * @param srcpad index of the output pad on the source filter<br>
	 * @param dst    the destination filter<br>
	 * @param dstpad index of the input pad on the destination filter<br>
	 * @return       zero on success<br>
	 * Original signature : <code>int avfilter_link(AVFilterContext*, unsigned, AVFilterContext*, unsigned)</code>
	 */
	int avfilter_link(AVFilterContext src, int srcpad, AVFilterContext dst, int dstpad);
	/**
	 * Free the link in *link, and set its pointer to NULL.<br>
	 * Original signature : <code>void avfilter_link_free(AVFilterLink**)</code><br>
	 * @deprecated use the safer method {@link #avfilter_link_free(org.javaavc.gen.avfilter.AVFilterLink.ByReference[])} instead
	 */
	@Deprecated 
	void avfilter_link_free(PointerByReference link);
	/**
	 * Free the link in *link, and set its pointer to NULL.<br>
	 * Original signature : <code>void avfilter_link_free(AVFilterLink**)</code>
	 */
	void avfilter_link_free(AVFilterLink.ByReference link[]);
	/**
	 * Get the number of channels of a link.<br>
	 * Original signature : <code>int avfilter_link_get_channels(AVFilterLink*)</code>
	 */
	int avfilter_link_get_channels(AVFilterLink link);
	/**
	 * Set the closed field of a link.<br>
	 * Original signature : <code>void avfilter_link_set_closed(AVFilterLink*, int)</code>
	 */
	void avfilter_link_set_closed(AVFilterLink link, int closed);
	/**
	 * Negotiate the media format, dimensions, etc of all inputs to a filter.<br>
	 * * @param filter the filter to negotiate the properties for its inputs<br>
	 * @return       zero on successful negotiation<br>
	 * Original signature : <code>int avfilter_config_links(AVFilterContext*)</code>
	 */
	int avfilter_config_links(AVFilterContext filter);
	/**
	 * Original signature : <code>AVFilterBufferRef* avfilter_get_video_buffer_ref_from_arrays(const uint8_t*[4], const int[4], int, int, int, AVPixelFormat)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_get_video_buffer_ref_from_arrays(java.nio.ByteBuffer[], java.nio.IntBuffer, int, int, int, int)} and {@link #avfilter_get_video_buffer_ref_from_arrays(com.sun.jna.ptr.PointerByReference, com.sun.jna.ptr.IntByReference, int, int, int, int)} instead
	 */
	@Deprecated 
	AVFilterBufferRef avfilter_get_video_buffer_ref_from_arrays(PointerByReference data, IntByReference linesize, int perms, int w, int h, int format);
	/** Original signature : <code>AVFilterBufferRef* avfilter_get_video_buffer_ref_from_arrays(const uint8_t*[4], const int[4], int, int, int, AVPixelFormat)</code> */
	AVFilterBufferRef avfilter_get_video_buffer_ref_from_arrays(ByteBuffer data[], IntBuffer linesize, int perms, int w, int h, int format);
	/** Original signature : <code>AVFilterBufferRef* avfilter_get_audio_buffer_ref_from_arrays(uint8_t**, int, int, int, AVSampleFormat, uint64_t)</code> */
	AVFilterBufferRef avfilter_get_audio_buffer_ref_from_arrays(PointerByReference data, int linesize, int perms, int nb_samples, int sample_fmt, long channel_layout);
	/** Original signature : <code>AVFilterBufferRef* avfilter_get_audio_buffer_ref_from_arrays_channels(uint8_t**, int, int, int, AVSampleFormat, int, uint64_t)</code> */
	AVFilterBufferRef avfilter_get_audio_buffer_ref_from_arrays_channels(PointerByReference data, int linesize, int perms, int nb_samples, int sample_fmt, int channels, long channel_layout);
	/**
	 * Make the filter instance process a command.<br>
	 * It is recommended to use avfilter_graph_send_command().<br>
	 * Original signature : <code>int avfilter_process_command(AVFilterContext*, const char*, const char*, char*, int, int)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_process_command(org.javaavc.gen.avfilter.AVFilterContext, java.lang.String, java.lang.String, java.nio.ByteBuffer, int, int)} and {@link #avfilter_process_command(org.javaavc.gen.avfilter.AVFilterContext, com.sun.jna.Pointer, com.sun.jna.Pointer, com.sun.jna.Pointer, int, int)} instead
	 */
	@Deprecated 
	int avfilter_process_command(AVFilterContext filter, Pointer cmd, Pointer arg, Pointer res, int res_len, int flags);
	/**
	 * Make the filter instance process a command.<br>
	 * It is recommended to use avfilter_graph_send_command().<br>
	 * Original signature : <code>int avfilter_process_command(AVFilterContext*, const char*, const char*, char*, int, int)</code>
	 */
	int avfilter_process_command(AVFilterContext filter, String cmd, String arg, ByteBuffer res, int res_len, int flags);
	/**
	 * Initialize the filter system. Register all builtin filters.<br>
	 * Original signature : <code>void avfilter_register_all()</code>
	 */
	void avfilter_register_all();
	/** Original signature : <code>void avfilter_uninit()</code> */
	void avfilter_uninit();
	/**
	 * Register a filter. This is only needed if you plan to use<br>
	 * avfilter_get_by_name later to lookup the AVFilter structure by name. A<br>
	 * filter can still by instantiated with avfilter_graph_alloc_filter even if it<br>
	 * is not registered.<br>
	 * * @param filter the filter to register<br>
	 * @return 0 if the registration was successful, a negative value<br>
	 * otherwise<br>
	 * Original signature : <code>int avfilter_register(AVFilter*)</code>
	 */
	int avfilter_register(AVFilter filter);
	/**
	 * Get a filter definition matching the given name.<br>
	 * * @param name the filter name to find<br>
	 * @return     the filter definition, if any matching one is registered.<br>
	 *             NULL if none found.<br>
	 * Original signature : <code>AVFilter* avfilter_get_by_name(const char*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_get_by_name(java.lang.String)} and {@link #avfilter_get_by_name(com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	AVFilter avfilter_get_by_name(Pointer name);
	/**
	 * Get a filter definition matching the given name.<br>
	 * * @param name the filter name to find<br>
	 * @return     the filter definition, if any matching one is registered.<br>
	 *             NULL if none found.<br>
	 * Original signature : <code>AVFilter* avfilter_get_by_name(const char*)</code>
	 */
	AVFilter avfilter_get_by_name(String name);
	/**
	 * Iterate over all registered filters.<br>
	 * @return If prev is non-NULL, next registered filter after prev or NULL if<br>
	 * prev is the last filter. If prev is NULL, return the first registered filter.<br>
	 * Original signature : <code>AVFilter* avfilter_next(const AVFilter*)</code>
	 */
	AVFilter avfilter_next(AVFilter prev);
	/**
	 * Original signature : <code>AVFilter** av_filter_next(AVFilter**)</code><br>
	 * @deprecated use the safer method {@link #av_filter_next(org.javaavc.gen.avfilter.AVFilter.ByReference[])} instead
	 */
	@Deprecated 
	AVFilter.ByReference[] av_filter_next(PointerByReference filter);
	/** Original signature : <code>AVFilter** av_filter_next(AVFilter**)</code> */
	AVFilter.ByReference[] av_filter_next(AVFilter.ByReference filter[]);
	/**
	 * Original signature : <code>int avfilter_open(AVFilterContext**, AVFilter*, const char*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_open(org.javaavc.gen.avfilter.AVFilterContext.ByReference[], org.javaavc.gen.avfilter.AVFilter, java.lang.String)} and {@link #avfilter_open(org.javaavc.gen.avfilter.AVFilterContext.ByReference[], org.javaavc.gen.avfilter.AVFilter, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	int avfilter_open(PointerByReference filter_ctx, AVFilter filter, Pointer inst_name);
	/** Original signature : <code>int avfilter_open(AVFilterContext**, AVFilter*, const char*)</code> */
	int avfilter_open(AVFilterContext.ByReference filter_ctx[], AVFilter filter, String inst_name);
	/** Original signature : <code>int avfilter_open(AVFilterContext**, AVFilter*, const char*)</code> */
	int avfilter_open(AVFilterContext.ByReference filter_ctx[], AVFilter filter, Pointer inst_name);
	/**
	 * Original signature : <code>int avfilter_init_filter(AVFilterContext*, const char*, void*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_init_filter(org.javaavc.gen.avfilter.AVFilterContext, java.lang.String, com.sun.jna.Pointer)} and {@link #avfilter_init_filter(org.javaavc.gen.avfilter.AVFilterContext, com.sun.jna.Pointer, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	int avfilter_init_filter(AVFilterContext filter, Pointer args, Pointer opaque);
	/** Original signature : <code>int avfilter_init_filter(AVFilterContext*, const char*, void*)</code> */
	int avfilter_init_filter(AVFilterContext filter, String args, Pointer opaque);
	/**
	 * Initialize a filter with the supplied parameters.<br>
	 * * @param ctx  uninitialized filter context to initialize<br>
	 * @param args Options to initialize the filter with. This must be a<br>
	 *             ':'-separated list of options in the 'key=value' form.<br>
	 *             May be NULL if the options have been set directly using the<br>
	 *             AVOptions API or there are no options that need to be set.<br>
	 * @return 0 on success, a negative AVERROR on failure<br>
	 * Original signature : <code>int avfilter_init_str(AVFilterContext*, const char*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_init_str(org.javaavc.gen.avfilter.AVFilterContext, java.lang.String)} and {@link #avfilter_init_str(org.javaavc.gen.avfilter.AVFilterContext, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	int avfilter_init_str(AVFilterContext ctx, Pointer args);
	/**
	 * Initialize a filter with the supplied parameters.<br>
	 * * @param ctx  uninitialized filter context to initialize<br>
	 * @param args Options to initialize the filter with. This must be a<br>
	 *             ':'-separated list of options in the 'key=value' form.<br>
	 *             May be NULL if the options have been set directly using the<br>
	 *             AVOptions API or there are no options that need to be set.<br>
	 * @return 0 on success, a negative AVERROR on failure<br>
	 * Original signature : <code>int avfilter_init_str(AVFilterContext*, const char*)</code>
	 */
	int avfilter_init_str(AVFilterContext ctx, String args);
	/**
	 * Initialize a filter with the supplied dictionary of options.<br>
	 * * @param ctx     uninitialized filter context to initialize<br>
	 * @param options An AVDictionary filled with options for this filter. On<br>
	 *                return this parameter will be destroyed and replaced with<br>
	 *                a dict containing options that were not found. This dictionary<br>
	 *                must be freed by the caller.<br>
	 *                May be NULL, then this function is equivalent to<br>
	 *                avfilter_init_str() with the second parameter set to NULL.<br>
	 * @return 0 on success, a negative AVERROR on failure<br>
	 * * @note This function and avfilter_init_str() do essentially the same thing,<br>
	 * the difference is in manner in which the options are passed. It is up to the<br>
	 * calling code to choose whichever is more preferable. The two functions also<br>
	 * behave differently when some of the provided options are not declared as<br>
	 * supported by the filter. In such a case, avfilter_init_str() will fail, but<br>
	 * this function will leave those extra options in the options AVDictionary and<br>
	 * continue as usual.<br>
	 * Original signature : <code>int avfilter_init_dict(AVFilterContext*, AVDictionary**)</code>
	 */
	int avfilter_init_dict(AVFilterContext ctx, PointerByReference options);
	/**
	 * Free a filter context. This will also remove the filter from its<br>
	 * filtergraph's list of filters.<br>
	 * * @param filter the filter to free<br>
	 * Original signature : <code>void avfilter_free(AVFilterContext*)</code>
	 */
	void avfilter_free(AVFilterContext filter);
	/**
	 * Insert a filter in the middle of an existing link.<br>
	 * * @param link the link into which the filter should be inserted<br>
	 * @param filt the filter to be inserted<br>
	 * @param filt_srcpad_idx the input pad on the filter to connect<br>
	 * @param filt_dstpad_idx the output pad on the filter to connect<br>
	 * @return     zero on success<br>
	 * Original signature : <code>int avfilter_insert_filter(AVFilterLink*, AVFilterContext*, unsigned, unsigned)</code>
	 */
	int avfilter_insert_filter(AVFilterLink link, AVFilterContext filt, int filt_srcpad_idx, int filt_dstpad_idx);
	/** Original signature : <code>int avfilter_copy_frame_props(AVFilterBufferRef*, const AVFrame*)</code> */
	int avfilter_copy_frame_props(AVFilterBufferRef dst, AVFrame src);
	/** Original signature : <code>int avfilter_copy_buf_props(AVFrame*, const AVFilterBufferRef*)</code> */
	int avfilter_copy_buf_props(AVFrame dst, AVFilterBufferRef src);
	/**
	 * @return AVClass for AVFilterContext.<br>
	 * * @see av_opt_find().<br>
	 * Original signature : <code>AVClass* avfilter_get_class()</code>
	 */
	AVClass avfilter_get_class();
	/**
	 * Allocate a filter graph.<br>
	 * Original signature : <code>AVFilterGraph* avfilter_graph_alloc()</code>
	 */
	AVFilterGraph avfilter_graph_alloc();
	/**
	 * Create a new filter instance in a filter graph.<br>
	 * * @param graph graph in which the new filter will be used<br>
	 * @param filter the filter to create an instance of<br>
	 * @param name Name to give to the new instance (will be copied to<br>
	 *             AVFilterContext.name). This may be used by the caller to identify<br>
	 *             different filters, libavfilter itself assigns no semantics to<br>
	 *             this parameter. May be NULL.<br>
	 * * @return the context of the newly created filter instance (note that it is<br>
	 *         also retrievable directly through AVFilterGraph.filters or with<br>
	 *         avfilter_graph_get_filter()) on success or NULL or failure.<br>
	 * Original signature : <code>AVFilterContext* avfilter_graph_alloc_filter(AVFilterGraph*, const AVFilter*, const char*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_alloc_filter(org.javaavc.gen.avfilter.AVFilterGraph, org.javaavc.gen.avfilter.AVFilter, java.lang.String)} and {@link #avfilter_graph_alloc_filter(org.javaavc.gen.avfilter.AVFilterGraph, org.javaavc.gen.avfilter.AVFilter, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	AVFilterContext avfilter_graph_alloc_filter(AVFilterGraph graph, AVFilter filter, Pointer name);
	/**
	 * Create a new filter instance in a filter graph.<br>
	 * * @param graph graph in which the new filter will be used<br>
	 * @param filter the filter to create an instance of<br>
	 * @param name Name to give to the new instance (will be copied to<br>
	 *             AVFilterContext.name). This may be used by the caller to identify<br>
	 *             different filters, libavfilter itself assigns no semantics to<br>
	 *             this parameter. May be NULL.<br>
	 * * @return the context of the newly created filter instance (note that it is<br>
	 *         also retrievable directly through AVFilterGraph.filters or with<br>
	 *         avfilter_graph_get_filter()) on success or NULL or failure.<br>
	 * Original signature : <code>AVFilterContext* avfilter_graph_alloc_filter(AVFilterGraph*, const AVFilter*, const char*)</code>
	 */
	AVFilterContext avfilter_graph_alloc_filter(AVFilterGraph graph, AVFilter filter, String name);
	/**
	 * Get a filter instance with name name from graph.<br>
	 * * @return the pointer to the found filter instance or NULL if it<br>
	 * cannot be found.<br>
	 * Original signature : <code>AVFilterContext* avfilter_graph_get_filter(AVFilterGraph*, char*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_get_filter(org.javaavc.gen.avfilter.AVFilterGraph, java.nio.ByteBuffer)} and {@link #avfilter_graph_get_filter(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	AVFilterContext avfilter_graph_get_filter(AVFilterGraph graph, Pointer name);
	/**
	 * Get a filter instance with name name from graph.<br>
	 * * @return the pointer to the found filter instance or NULL if it<br>
	 * cannot be found.<br>
	 * Original signature : <code>AVFilterContext* avfilter_graph_get_filter(AVFilterGraph*, char*)</code>
	 */
	AVFilterContext avfilter_graph_get_filter(AVFilterGraph graph, ByteBuffer name);
	/** Original signature : <code>int avfilter_graph_add_filter(AVFilterGraph*, AVFilterContext*)</code> */
	int avfilter_graph_add_filter(AVFilterGraph graphctx, AVFilterContext filter);
	/**
	 * Create and add a filter instance into an existing graph.<br>
	 * The filter instance is created from the filter filt and inited<br>
	 * with the parameters args and opaque.<br>
	 * * In case of success put in *filt_ctx the pointer to the created<br>
	 * filter instance, otherwise set *filt_ctx to NULL.<br>
	 * * @param name the instance name to give to the created filter instance<br>
	 * @param graph_ctx the filter graph<br>
	 * @return a negative AVERROR error code in case of failure, a non<br>
	 * negative value otherwise<br>
	 * Original signature : <code>int avfilter_graph_create_filter(AVFilterContext**, AVFilter*, const char*, const char*, void*, AVFilterGraph*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_create_filter(org.javaavc.gen.avfilter.AVFilterContext.ByReference[], org.javaavc.gen.avfilter.AVFilter, java.lang.String, java.lang.String, com.sun.jna.Pointer, org.javaavc.gen.avfilter.AVFilterGraph)} and {@link #avfilter_graph_create_filter(org.javaavc.gen.avfilter.AVFilterContext.ByReference[], org.javaavc.gen.avfilter.AVFilter, com.sun.jna.Pointer, com.sun.jna.Pointer, com.sun.jna.Pointer, org.javaavc.gen.avfilter.AVFilterGraph)} instead
	 */
	@Deprecated 
	int avfilter_graph_create_filter(PointerByReference filt_ctx, AVFilter filt, Pointer name, Pointer args, Pointer opaque, AVFilterGraph graph_ctx);
	/**
	 * Create and add a filter instance into an existing graph.<br>
	 * The filter instance is created from the filter filt and inited<br>
	 * with the parameters args and opaque.<br>
	 * * In case of success put in *filt_ctx the pointer to the created<br>
	 * filter instance, otherwise set *filt_ctx to NULL.<br>
	 * * @param name the instance name to give to the created filter instance<br>
	 * @param graph_ctx the filter graph<br>
	 * @return a negative AVERROR error code in case of failure, a non<br>
	 * negative value otherwise<br>
	 * Original signature : <code>int avfilter_graph_create_filter(AVFilterContext**, AVFilter*, const char*, const char*, void*, AVFilterGraph*)</code>
	 */
	int avfilter_graph_create_filter(AVFilterContext.ByReference filt_ctx[], AVFilter filt, String name, String args, Pointer opaque, AVFilterGraph graph_ctx);
	/**
	 * Create and add a filter instance into an existing graph.<br>
	 * The filter instance is created from the filter filt and inited<br>
	 * with the parameters args and opaque.<br>
	 * * In case of success put in *filt_ctx the pointer to the created<br>
	 * filter instance, otherwise set *filt_ctx to NULL.<br>
	 * * @param name the instance name to give to the created filter instance<br>
	 * @param graph_ctx the filter graph<br>
	 * @return a negative AVERROR error code in case of failure, a non<br>
	 * negative value otherwise<br>
	 * Original signature : <code>int avfilter_graph_create_filter(AVFilterContext**, AVFilter*, const char*, const char*, void*, AVFilterGraph*)</code>
	 */
	int avfilter_graph_create_filter(AVFilterContext.ByReference filt_ctx[], AVFilter filt, Pointer name, Pointer args, Pointer opaque, AVFilterGraph graph_ctx);
	/**
	 * Enable or disable automatic format conversion inside the graph.<br>
	 * * Note that format conversion can still happen inside explicitly inserted<br>
	 * scale and aresample filters.<br>
	 * * @param flags  any of the AVFILTER_AUTO_CONVERT_* constants<br>
	 * Original signature : <code>void avfilter_graph_set_auto_convert(AVFilterGraph*, unsigned)</code>
	 */
	void avfilter_graph_set_auto_convert(AVFilterGraph graph, int flags);
	/**
	 * Check validity and configure all the links and formats in the graph.<br>
	 * * @param graphctx the filter graph<br>
	 * @param log_ctx context used for logging<br>
	 * @return 0 in case of success, a negative AVERROR code otherwise<br>
	 * Original signature : <code>int avfilter_graph_config(AVFilterGraph*, void*)</code>
	 */
	int avfilter_graph_config(AVFilterGraph graphctx, Pointer log_ctx);
	/**
	 * Free a graph, destroy its links, and set *graph to NULL.<br>
	 * If *graph is NULL, do nothing.<br>
	 * Original signature : <code>void avfilter_graph_free(AVFilterGraph**)</code><br>
	 * @deprecated use the safer method {@link #avfilter_graph_free(org.javaavc.gen.avfilter.AVFilterGraph.ByReference[])} instead
	 */
	@Deprecated 
	void avfilter_graph_free(PointerByReference graph);
	/**
	 * Free a graph, destroy its links, and set *graph to NULL.<br>
	 * If *graph is NULL, do nothing.<br>
	 * Original signature : <code>void avfilter_graph_free(AVFilterGraph**)</code>
	 */
	void avfilter_graph_free(AVFilterGraph.ByReference graph[]);
	/**
	 * Allocate a single AVFilterInOut entry.<br>
	 * Must be freed with avfilter_inout_free().<br>
	 * @return allocated AVFilterInOut on success, NULL on failure.<br>
	 * Original signature : <code>AVFilterInOut* avfilter_inout_alloc()</code>
	 */
	AVFilterInOut avfilter_inout_alloc();
	/**
	 * Free the supplied list of AVFilterInOut and set *inout to NULL.<br>
	 * If *inout is NULL, do nothing.<br>
	 * Original signature : <code>void avfilter_inout_free(AVFilterInOut**)</code><br>
	 * @deprecated use the safer method {@link #avfilter_inout_free(org.javaavc.gen.avfilter.AVFilterInOut.ByReference[])} instead
	 */
	@Deprecated 
	void avfilter_inout_free(PointerByReference inout);
	/**
	 * Free the supplied list of AVFilterInOut and set *inout to NULL.<br>
	 * If *inout is NULL, do nothing.<br>
	 * Original signature : <code>void avfilter_inout_free(AVFilterInOut**)</code>
	 */
	void avfilter_inout_free(AVFilterInOut.ByReference inout[]);
	/**
	 * Original signature : <code>int avfilter_graph_parse(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**, void*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_parse(org.javaavc.gen.avfilter.AVFilterGraph, java.lang.String, org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], com.sun.jna.Pointer)} and {@link #avfilter_graph_parse(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer, org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	int avfilter_graph_parse(AVFilterGraph graph, Pointer filters, PointerByReference inputs, PointerByReference outputs, Pointer log_ctx);
	/** Original signature : <code>int avfilter_graph_parse(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**, void*)</code> */
	int avfilter_graph_parse(AVFilterGraph graph, String filters, AVFilterInOut.ByReference inputs[], AVFilterInOut.ByReference outputs[], Pointer log_ctx);
	/** Original signature : <code>int avfilter_graph_parse(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**, void*)</code> */
	int avfilter_graph_parse(AVFilterGraph graph, Pointer filters, AVFilterInOut.ByReference inputs[], AVFilterInOut.ByReference outputs[], Pointer log_ctx);
	/**
	 * Add a graph described by a string to a graph.<br>
	 * * @param graph   the filter graph where to link the parsed graph context<br>
	 * @param filters string to be parsed<br>
	 * @param inputs  pointer to a linked list to the inputs of the graph, may be NULL.<br>
	 *                If non-NULL, *inputs is updated to contain the list of open inputs<br>
	 *                after the parsing, should be freed with avfilter_inout_free().<br>
	 * @param outputs pointer to a linked list to the outputs of the graph, may be NULL.<br>
	 *                If non-NULL, *outputs is updated to contain the list of open outputs<br>
	 *                after the parsing, should be freed with avfilter_inout_free().<br>
	 * @return non negative on success, a negative AVERROR code on error<br>
	 * Original signature : <code>int avfilter_graph_parse_ptr(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**, void*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_parse_ptr(org.javaavc.gen.avfilter.AVFilterGraph, java.lang.String, org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], com.sun.jna.Pointer)} and {@link #avfilter_graph_parse_ptr(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer, org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	int avfilter_graph_parse_ptr(AVFilterGraph graph, Pointer filters, PointerByReference inputs, PointerByReference outputs, Pointer log_ctx);
	/**
	 * Add a graph described by a string to a graph.<br>
	 * * @param graph   the filter graph where to link the parsed graph context<br>
	 * @param filters string to be parsed<br>
	 * @param inputs  pointer to a linked list to the inputs of the graph, may be NULL.<br>
	 *                If non-NULL, *inputs is updated to contain the list of open inputs<br>
	 *                after the parsing, should be freed with avfilter_inout_free().<br>
	 * @param outputs pointer to a linked list to the outputs of the graph, may be NULL.<br>
	 *                If non-NULL, *outputs is updated to contain the list of open outputs<br>
	 *                after the parsing, should be freed with avfilter_inout_free().<br>
	 * @return non negative on success, a negative AVERROR code on error<br>
	 * Original signature : <code>int avfilter_graph_parse_ptr(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**, void*)</code>
	 */
	int avfilter_graph_parse_ptr(AVFilterGraph graph, String filters, AVFilterInOut.ByReference inputs[], AVFilterInOut.ByReference outputs[], Pointer log_ctx);
	/**
	 * Add a graph described by a string to a graph.<br>
	 * * @param graph   the filter graph where to link the parsed graph context<br>
	 * @param filters string to be parsed<br>
	 * @param inputs  pointer to a linked list to the inputs of the graph, may be NULL.<br>
	 *                If non-NULL, *inputs is updated to contain the list of open inputs<br>
	 *                after the parsing, should be freed with avfilter_inout_free().<br>
	 * @param outputs pointer to a linked list to the outputs of the graph, may be NULL.<br>
	 *                If non-NULL, *outputs is updated to contain the list of open outputs<br>
	 *                after the parsing, should be freed with avfilter_inout_free().<br>
	 * @return non negative on success, a negative AVERROR code on error<br>
	 * Original signature : <code>int avfilter_graph_parse_ptr(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**, void*)</code>
	 */
	int avfilter_graph_parse_ptr(AVFilterGraph graph, Pointer filters, AVFilterInOut.ByReference inputs[], AVFilterInOut.ByReference outputs[], Pointer log_ctx);
	/**
	 * Add a graph described by a string to a graph.<br>
	 * * @param[in]  graph   the filter graph where to link the parsed graph context<br>
	 * @param[in]  filters string to be parsed<br>
	 * @param[out] inputs  a linked list of all free (unlinked) inputs of the<br>
	 *                     parsed graph will be returned here. It is to be freed<br>
	 *                     by the caller using avfilter_inout_free().<br>
	 * @param[out] outputs a linked list of all free (unlinked) outputs of the<br>
	 *                     parsed graph will be returned here. It is to be freed by the<br>
	 *                     caller using avfilter_inout_free().<br>
	 * @return zero on success, a negative AVERROR code on error<br>
	 * * @note This function returns the inputs and outputs that are left<br>
	 * unlinked after parsing the graph and the caller then deals with<br>
	 * them.<br>
	 * @note This function makes no reference whatsoever to already<br>
	 * existing parts of the graph and the inputs parameter will on return<br>
	 * contain inputs of the newly parsed part of the graph.  Analogously<br>
	 * the outputs parameter will contain outputs of the newly created<br>
	 * filters.<br>
	 * Original signature : <code>int avfilter_graph_parse2(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_parse2(org.javaavc.gen.avfilter.AVFilterGraph, java.lang.String, org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], org.javaavc.gen.avfilter.AVFilterInOut.ByReference[])} and {@link #avfilter_graph_parse2(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer, org.javaavc.gen.avfilter.AVFilterInOut.ByReference[], org.javaavc.gen.avfilter.AVFilterInOut.ByReference[])} instead
	 */
	@Deprecated 
	int avfilter_graph_parse2(AVFilterGraph graph, Pointer filters, PointerByReference inputs, PointerByReference outputs);
	/**
	 * Add a graph described by a string to a graph.<br>
	 * * @param[in]  graph   the filter graph where to link the parsed graph context<br>
	 * @param[in]  filters string to be parsed<br>
	 * @param[out] inputs  a linked list of all free (unlinked) inputs of the<br>
	 *                     parsed graph will be returned here. It is to be freed<br>
	 *                     by the caller using avfilter_inout_free().<br>
	 * @param[out] outputs a linked list of all free (unlinked) outputs of the<br>
	 *                     parsed graph will be returned here. It is to be freed by the<br>
	 *                     caller using avfilter_inout_free().<br>
	 * @return zero on success, a negative AVERROR code on error<br>
	 * * @note This function returns the inputs and outputs that are left<br>
	 * unlinked after parsing the graph and the caller then deals with<br>
	 * them.<br>
	 * @note This function makes no reference whatsoever to already<br>
	 * existing parts of the graph and the inputs parameter will on return<br>
	 * contain inputs of the newly parsed part of the graph.  Analogously<br>
	 * the outputs parameter will contain outputs of the newly created<br>
	 * filters.<br>
	 * Original signature : <code>int avfilter_graph_parse2(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**)</code>
	 */
	int avfilter_graph_parse2(AVFilterGraph graph, String filters, AVFilterInOut.ByReference inputs[], AVFilterInOut.ByReference outputs[]);
	/**
	 * Add a graph described by a string to a graph.<br>
	 * * @param[in]  graph   the filter graph where to link the parsed graph context<br>
	 * @param[in]  filters string to be parsed<br>
	 * @param[out] inputs  a linked list of all free (unlinked) inputs of the<br>
	 *                     parsed graph will be returned here. It is to be freed<br>
	 *                     by the caller using avfilter_inout_free().<br>
	 * @param[out] outputs a linked list of all free (unlinked) outputs of the<br>
	 *                     parsed graph will be returned here. It is to be freed by the<br>
	 *                     caller using avfilter_inout_free().<br>
	 * @return zero on success, a negative AVERROR code on error<br>
	 * * @note This function returns the inputs and outputs that are left<br>
	 * unlinked after parsing the graph and the caller then deals with<br>
	 * them.<br>
	 * @note This function makes no reference whatsoever to already<br>
	 * existing parts of the graph and the inputs parameter will on return<br>
	 * contain inputs of the newly parsed part of the graph.  Analogously<br>
	 * the outputs parameter will contain outputs of the newly created<br>
	 * filters.<br>
	 * Original signature : <code>int avfilter_graph_parse2(AVFilterGraph*, const char*, AVFilterInOut**, AVFilterInOut**)</code>
	 */
	int avfilter_graph_parse2(AVFilterGraph graph, Pointer filters, AVFilterInOut.ByReference inputs[], AVFilterInOut.ByReference outputs[]);
	/**
	 * Send a command to one or more filter instances.<br>
	 * * @param graph  the filter graph<br>
	 * @param target the filter(s) to which the command should be sent<br>
	 *               "all" sends to all filters<br>
	 *               otherwise it can be a filter or filter instance name<br>
	 *               which will send the command to all matching filters.<br>
	 * @param cmd    the command to send, for handling simplicity all commands must be alphanumeric only<br>
	 * @param arg    the argument for the command<br>
	 * @param res    a buffer with size res_size where the filter(s) can return a response.<br>
	 * * @returns >=0 on success otherwise an error code.<br>
	 *              AVERROR(ENOSYS) on unsupported commands<br>
	 * Original signature : <code>int avfilter_graph_send_command(AVFilterGraph*, const char*, const char*, const char*, char*, int, int)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_send_command(org.javaavc.gen.avfilter.AVFilterGraph, java.lang.String, java.lang.String, java.lang.String, java.nio.ByteBuffer, int, int)} and {@link #avfilter_graph_send_command(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer, com.sun.jna.Pointer, com.sun.jna.Pointer, com.sun.jna.Pointer, int, int)} instead
	 */
	@Deprecated 
	int avfilter_graph_send_command(AVFilterGraph graph, Pointer target, Pointer cmd, Pointer arg, Pointer res, int res_len, int flags);
	/**
	 * Send a command to one or more filter instances.<br>
	 * * @param graph  the filter graph<br>
	 * @param target the filter(s) to which the command should be sent<br>
	 *               "all" sends to all filters<br>
	 *               otherwise it can be a filter or filter instance name<br>
	 *               which will send the command to all matching filters.<br>
	 * @param cmd    the command to send, for handling simplicity all commands must be alphanumeric only<br>
	 * @param arg    the argument for the command<br>
	 * @param res    a buffer with size res_size where the filter(s) can return a response.<br>
	 * * @returns >=0 on success otherwise an error code.<br>
	 *              AVERROR(ENOSYS) on unsupported commands<br>
	 * Original signature : <code>int avfilter_graph_send_command(AVFilterGraph*, const char*, const char*, const char*, char*, int, int)</code>
	 */
	int avfilter_graph_send_command(AVFilterGraph graph, String target, String cmd, String arg, ByteBuffer res, int res_len, int flags);
	/**
	 * Queue a command for one or more filter instances.<br>
	 * * @param graph  the filter graph<br>
	 * @param target the filter(s) to which the command should be sent<br>
	 *               "all" sends to all filters<br>
	 *               otherwise it can be a filter or filter instance name<br>
	 *               which will send the command to all matching filters.<br>
	 * @param cmd    the command to sent, for handling simplicity all commands must be alphanummeric only<br>
	 * @param arg    the argument for the command<br>
	 * @param ts     time at which the command should be sent to the filter<br>
	 * * @note As this executes commands after this function returns, no return code<br>
	 *       from the filter is provided, also AVFILTER_CMD_FLAG_ONE is not supported.<br>
	 * Original signature : <code>int avfilter_graph_queue_command(AVFilterGraph*, const char*, const char*, const char*, int, double)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_queue_command(org.javaavc.gen.avfilter.AVFilterGraph, java.lang.String, java.lang.String, java.lang.String, int, double)} and {@link #avfilter_graph_queue_command(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer, com.sun.jna.Pointer, com.sun.jna.Pointer, int, double)} instead
	 */
	@Deprecated 
	int avfilter_graph_queue_command(AVFilterGraph graph, Pointer target, Pointer cmd, Pointer arg, int flags, double ts);
	/**
	 * Queue a command for one or more filter instances.<br>
	 * * @param graph  the filter graph<br>
	 * @param target the filter(s) to which the command should be sent<br>
	 *               "all" sends to all filters<br>
	 *               otherwise it can be a filter or filter instance name<br>
	 *               which will send the command to all matching filters.<br>
	 * @param cmd    the command to sent, for handling simplicity all commands must be alphanummeric only<br>
	 * @param arg    the argument for the command<br>
	 * @param ts     time at which the command should be sent to the filter<br>
	 * * @note As this executes commands after this function returns, no return code<br>
	 *       from the filter is provided, also AVFILTER_CMD_FLAG_ONE is not supported.<br>
	 * Original signature : <code>int avfilter_graph_queue_command(AVFilterGraph*, const char*, const char*, const char*, int, double)</code>
	 */
	int avfilter_graph_queue_command(AVFilterGraph graph, String target, String cmd, String arg, int flags, double ts);
	/**
	 * Dump a graph into a human-readable string representation.<br>
	 * * @param graph    the graph to dump<br>
	 * @param options  formatting options; currently ignored<br>
	 * @return  a string, or NULL in case of memory allocation failure;<br>
	 *          the string must be freed using av_free<br>
	 * Original signature : <code>char* avfilter_graph_dump(AVFilterGraph*, const char*)</code><br>
	 * @deprecated use the safer methods {@link #avfilter_graph_dump(org.javaavc.gen.avfilter.AVFilterGraph, java.lang.String)} and {@link #avfilter_graph_dump(org.javaavc.gen.avfilter.AVFilterGraph, com.sun.jna.Pointer)} instead
	 */
	@Deprecated 
	Pointer avfilter_graph_dump(AVFilterGraph graph, Pointer options);
	/**
	 * Dump a graph into a human-readable string representation.<br>
	 * * @param graph    the graph to dump<br>
	 * @param options  formatting options; currently ignored<br>
	 * @return  a string, or NULL in case of memory allocation failure;<br>
	 *          the string must be freed using av_free<br>
	 * Original signature : <code>char* avfilter_graph_dump(AVFilterGraph*, const char*)</code>
	 */
	Pointer avfilter_graph_dump(AVFilterGraph graph, String options);
	/**
	 * Request a frame on the oldest sink link.<br>
	 * * If the request returns AVERROR_EOF, try the next.<br>
	 * * Note that this function is not meant to be the sole scheduling mechanism<br>
	 * of a filtergraph, only a convenience function to help drain a filtergraph<br>
	 * in a balanced way under normal circumstances.<br>
	 * * Also note that AVERROR_EOF does not mean that frames did not arrive on<br>
	 * some of the sinks during the process.<br>
	 * When there are multiple sink links, in case the requested link<br>
	 * returns an EOF, this may cause a filter to flush pending frames<br>
	 * which are sent to another sink link, although unrequested.<br>
	 * * @return  the return value of ff_request_frame(),<br>
	 *          or AVERROR_EOF if all links returned AVERROR_EOF<br>
	 * Original signature : <code>int avfilter_graph_request_oldest(AVFilterGraph*)</code>
	 */
	int avfilter_graph_request_oldest(AVFilterGraph graph);
	public static class AVPanScan extends PointerType {
		public AVPanScan(Pointer address) {
			super(address);
		}
		public AVPanScan() {
			super();
		}
	};
	public static class AVFilterChannelLayouts extends PointerType {
		public AVFilterChannelLayouts(Pointer address) {
			super(address);
		}
		public AVFilterChannelLayouts() {
			super();
		}
	};
	public static class AVFilterCommand extends PointerType {
		public AVFilterCommand(Pointer address) {
			super(address);
		}
		public AVFilterCommand() {
			super();
		}
	};
	public static class AVFilterFormats extends PointerType {
		public AVFilterFormats(Pointer address) {
			super(address);
		}
		public AVFilterFormats() {
			super();
		}
	};
	public static class AVFilterPool extends PointerType {
		public AVFilterPool(Pointer address) {
			super(address);
		}
		public AVFilterPool() {
			super();
		}
	};
	public static class AVBufferPool extends PointerType {
		public AVBufferPool(Pointer address) {
			super(address);
		}
		public AVBufferPool() {
			super();
		}
	};
	public static class AVOption extends PointerType {
		public AVOption(Pointer address) {
			super(address);
		}
		public AVOption() {
			super();
		}
	};
	public static class AVFilterInternal extends PointerType {
		public AVFilterInternal(Pointer address) {
			super(address);
		}
		public AVFilterInternal() {
			super();
		}
	};
	public static class AVBuffer extends PointerType {
		public AVBuffer(Pointer address) {
			super(address);
		}
		public AVBuffer() {
			super();
		}
	};
	public static class AVFilterGraphInternal extends PointerType {
		public AVFilterGraphInternal(Pointer address) {
			super(address);
		}
		public AVFilterGraphInternal() {
			super();
		}
	};
	public static class va_list extends PointerType {
		public va_list(Pointer address) {
			super(address);
		}
		public va_list() {
			super();
		}
	};
	public static class AVCodecContext extends PointerType {
		public AVCodecContext(Pointer address) {
			super(address);
		}
		public AVCodecContext() {
			super();
		}
	};
	public static class AVDictionary extends PointerType {
		public AVDictionary(Pointer address) {
			super(address);
		}
		public AVDictionary() {
			super();
		}
	};
}
