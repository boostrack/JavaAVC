package org.javaavc.gen.avformat;
import com.sun.jna.Pointer;
import com.sun.jna.Structure;
import com.sun.jna.ptr.PointerByReference;
import java.util.Arrays;
import java.util.List;
import org.javaavc.gen.avformat.LibavformatLibrary.AVDiscard;
/**
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> , <a href="http://rococoa.dev.java.net/">Rococoa</a>, or <a href="http://jna.dev.java.net/">JNA</a>.
 */
public abstract class AVStream extends Structure {
	/** < stream index in AVFormatContext */
	public int index;
	/**
	 * Format-specific stream ID.<br>
	 * decoding: set by libavformat<br>
	 * encoding: set by the user, replaced by libavformat if left unset
	 */
	public int id;
	/**
	 * Codec context associated with this stream. Allocated and freed by<br>
	 * libavformat.<br>
	 * * - decoding: The demuxer exports codec information stored in the headers<br>
	 *             here.<br>
	 * - encoding: The user sets codec information, the muxer writes it to the<br>
	 *             output. Mandatory fields as specified in AVCodecContext<br>
	 *             documentation must be set even if this AVCodecContext is<br>
	 *             not actually used for encoding.<br>
	 * C type : AVCodecContext*
	 */
	public Pointer codec;
	/**
	 * Conversion Error : struct AVRational {<br>
	 * 	int num; ///< numerator<br>
	 * <br>
	 * 	int den; ///< denominator<br>
	 * <br>
	 * }
	 */
	/** C type : void* */
	public Pointer priv_data;
	/**
	 * encoding: pts generation when outputting stream<br>
	 * C type : AVFrac
	 */
	public AVFrac pts;
	/**
	 * Conversion Error : struct AVRational {<br>
	 * 	int num; ///< numerator<br>
	 * <br>
	 * 	int den; ///< denominator<br>
	 * <br>
	 * }
	 */
	/**
	 * Decoding: pts of the first frame of the stream in presentation order, in stream time base.<br>
	 * Only set this if you are absolutely 100% sure that the value you set<br>
	 * it to really is the pts of the first frame.<br>
	 * This may be undefined (AV_NOPTS_VALUE).<br>
	 * @note The ASF header does NOT contain a correct start_time the ASF<br>
	 * demuxer must NOT set this.
	 */
	public long start_time;
	/**
	 * Decoding: duration of the stream, in stream time base.<br>
	 * If a source file does not specify a duration, but does specify<br>
	 * a bitrate, this value will be estimated from bitrate and file size.
	 */
	public long duration;
	/** < number of frames in this stream if known or 0 */
	public long nb_frames;
	/** < AV_DISPOSITION_* bit field */
	public int disposition;
	/**
	 * < Selects which packets can be discarded at will and do not need to be demuxed.<br>
	 * C type : AVDiscard
	 */
	public AVDiscard discard;
	/**
	 * Conversion Error : struct AVRational {<br>
	 * 	int num; ///< numerator<br>
	 * <br>
	 * 	int den; ///< denominator<br>
	 * <br>
	 * }
	 */
	/** C type : AVDictionary* */
	public PointerByReference metadata;
	/**
	 * Conversion Error : struct AVRational {<br>
	 * 	int num; ///< numerator<br>
	 * <br>
	 * 	int den; ///< denominator<br>
	 * <br>
	 * }
	 */
	/**
	 * Conversion Error : struct AVPacket {<br>
	 * 	/**<br>
	 * 	 * Presentation timestamp in AVStream->time_base units; the time at which<br>
	 * 	 * the decompressed packet will be presented to the user.<br>
	 * 	 * Can be AV_NOPTS_VALUE if it is not stored in the file.<br>
	 * 	 * pts MUST be larger or equal to dts as presentation cannot happen before<br>
	 * 	 * decompression, unless one wants to view hex dumps. Some formats misuse<br>
	 * 	 * the terms dts and pts/cts to mean something different. Such timestamps<br>
	 * 	 * must be converted to true pts/dts before they are stored in AVPacket.<br>
	 * 	 * /<br>
	 * 	int64_t pts;<br>
	 * 	/**<br>
	 * 	 * Decompression timestamp in AVStream->time_base units; the time at which<br>
	 * 	 * the packet is decompressed.<br>
	 * 	 * Can be AV_NOPTS_VALUE if it is not stored in the file.<br>
	 * 	 * /<br>
	 * 	int64_t dts;<br>
	 * 	uint8_t* data;<br>
	 * 	int size;<br>
	 * 	int stream_index;<br>
	 * 	/** A combination of AV_PKT_FLAG values * /<br>
	 * 	int flags;<br>
	 * 	/**<br>
	 * 	 * Additional packet data that can be provided by the container.<br>
	 * 	 * Packet can contain several types of side information.<br>
	 * 	 * /<br>
	 * 	side_data_struct* side_data;<br>
	 * 	int side_data_elems;<br>
	 * 	/**<br>
	 * 	 * Duration of this packet in AVStream->time_base units, 0 if unknown.<br>
	 * 	 * Equals next_pts - this_pts in presentation order.<br>
	 * 	 * /<br>
	 * 	int duration;<br>
	 * 	destruct_callback* destruct;<br>
	 * 	void* priv;<br>
	 * 	int64_t pos; ///< byte position in stream, -1 if unknown<br>
	 * <br>
	 * 	/**<br>
	 * 	 * Time difference in AVStream->time_base units from the pts of this<br>
	 * 	 * packet to the point at which the output from the decoder has converged<br>
	 * 	 * independent from the availability of previous frames. That is, the<br>
	 * 	 * frames are virtually identical no matter if decoding started from<br>
	 * 	 * the very first frame or from this keyframe.<br>
	 * 	 * Is AV_NOPTS_VALUE if unknown.<br>
	 * 	 * This field is not the display duration of the current packet.<br>
	 * 	 * This field has no meaning if the packet does not have AV_PKT_FLAG_KEY<br>
	 * 	 * set.<br>
	 * 	 * * The purpose of this field is to allow seeking in streams that have no<br>
	 * 	 * keyframes in the conventional sense. It corresponds to the<br>
	 * 	 * recovery point SEI in H.264 and match_time_delta in NUT. It is also<br>
	 * 	 * essential for some types of subtitle streams to ensure that all<br>
	 * 	 * subtitles are correctly displayed after seeking.<br>
	 * 	 * /<br>
	 * 	int64_t convergence_duration;<br>
	 * 	struct side_data_struct {<br>
	 * 		uint8_t* data;<br>
	 * 		int size;<br>
	 * 		AVPacketSideDataType type;<br>
	 * 		enum AVPacketSideDataType {<br>
	 * 		};<br>
	 * 	};<br>
	 * 	typedef void destruct_callback(AVPacket* AVPacketPtr1);<br>
	 * }
	 */
	/** C type : info_struct* */
	public AVStream.info_struct.ByReference info;
	/** < number of bits in pts (used for wrapping control) */
	public int pts_wrap_bits;
	/**
	 * Timestamp corresponding to the last dts sync point.<br>
	 * * Initialized when AVCodecParserContext.dts_sync_point >= 0 and<br>
	 * a DTS is received from the underlying container. Otherwise set to<br>
	 * AV_NOPTS_VALUE by default.
	 */
	public long reference_dts;
	public long first_dts;
	public long cur_dts;
	public long last_IP_pts;
	public int last_IP_duration;
	public int probe_packets;
	/** Number of frames that have been demuxed during av_find_stream_info() */
	public int codec_info_nb_frames;
	/**
	 * Stream Identifier<br>
	 * This is the MPEG-TS stream identifier +1<br>
	 * 0 means unknown
	 */
	public int stream_identifier;
	public long interleaver_chunk_size;
	public long interleaver_chunk_duration;
	/**
	 * av_read_frame() support<br>
	 * @see AVStreamParseType<br>
	 * C type : AVStreamParseType
	 */
	public int need_parsing;
	/** C type : AVCodecParserContext* */
	public Pointer parser;
	/**
	 * last packet in packet_buffer for this stream when muxing.<br>
	 * C type : AVPacketList*
	 */
	public org.javaavc.gen.avformat.AVPacketList.ByReference last_in_packet_buffer;
	/** C type : AVProbeData */
	public AVProbeData probe_data;
	/** C type : int64_t[16 + 1] */
	public long[] pts_buffer = new long[16 + 1];
	/**
	 * < Only used if the format does not<br>
	 * support seeking natively.<br>
	 * C type : AVIndexEntry*
	 */
	public org.javaavc.gen.avformat.AVIndexEntry.ByReference index_entries;
	public int nb_index_entries;
	public int index_entries_allocated_size;
	/**
	 * stream probing state<br>
	 * -1   -> probing finished<br>
	 *  0   -> no probing requested<br>
	 * rest -> perform probing with request_probe being the minimum score to accept.<br>
	 * NOT PART OF PUBLIC API
	 */
	public int request_probe;
	/**
	 * Indicates that everything up to the next keyframe<br>
	 * should be discarded.
	 */
	public int skip_to_keyframe;
	/** Number of samples to skip at the start of the frame decoded from the next packet. */
	public int skip_samples;
	/**
	 * Number of internally decoded frames, used internally in libavformat, do not access<br>
	 * its lifetime differs from info which is why it is not in that structure.
	 */
	public int nb_decoded_frames;
	/**
	 * Timestamp offset added to timestamps before muxing<br>
	 * NOT PART OF PUBLIC API
	 */
	public long mux_ts_offset;
	/** Internal data to check for wrapping of the time stamp */
	public long pts_wrap_reference;
	/**
	 * Options for behavior, when a wrap is detected.<br>
	 * * Defined by AV_PTS_WRAP_ values.<br>
	 * * If correction is enabled, there are two possibilities:<br>
	 * If the first time stamp is near the wrap point, the wrap offset<br>
	 * will be subtracted, which will create negative time stamps.<br>
	 * Otherwise the offset will be added.
	 */
	public int pts_wrap_behavior;
	public static class info_struct extends Structure {
		public long last_dts;
		public long duration_gcd;
		public int duration_count;
		/** C type : double[2][(60 * 12 + 6)]* */
		public Pointer duration_error;
		public long codec_info_duration;
		public long codec_info_duration_fields;
		public int found_decoder;
		public long last_duration;
		/** Those are used for average framerate estimation. */
		public long fps_first_dts;
		public int fps_first_dts_idx;
		public long fps_last_dts;
		public int fps_last_dts_idx;
		public info_struct() {
			super();
		}
		protected List<? > getFieldOrder() {
			return Arrays.asList("last_dts", "duration_gcd", "duration_count", "duration_error", "codec_info_duration", "codec_info_duration_fields", "found_decoder", "last_duration", "fps_first_dts", "fps_first_dts_idx", "fps_last_dts", "fps_last_dts_idx");
		}
		public static class ByReference extends info_struct implements Structure.ByReference {
			
		};
		public static class ByValue extends info_struct implements Structure.ByValue {
			
		};
	};
	public AVStream() {
		super();
	}
	protected List<? > getFieldOrder() {
		return Arrays.asList("index", "id", "codec", "priv_data", "pts", "start_time", "duration", "nb_frames", "disposition", "discard", "metadata", "info", "pts_wrap_bits", "reference_dts", "first_dts", "cur_dts", "last_IP_pts", "last_IP_duration", "probe_packets", "codec_info_nb_frames", "stream_identifier", "interleaver_chunk_size", "interleaver_chunk_duration", "need_parsing", "parser", "last_in_packet_buffer", "probe_data", "pts_buffer", "index_entries", "nb_index_entries", "index_entries_allocated_size", "request_probe", "skip_to_keyframe", "skip_samples", "nb_decoded_frames", "mux_ts_offset", "pts_wrap_reference", "pts_wrap_behavior");
	}
	public static abstract class ByReference extends AVStream implements Structure.ByReference {
		
	};
	public static abstract class ByValue extends AVStream implements Structure.ByValue {
		
	};
}
